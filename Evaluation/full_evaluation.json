{
    "49": {
        "accuracy od1": 0.6610089520164487,
        "precision od1": 0.6261984720378487,
        "recall od1": 1.0,
        "f1_score od1": 0.7701378187290221,
        "iou od1": 0.6261984720378487,
        "accuracy od2": 0.5869290612304301,
        "precision od2": 0.6934782608695652,
        "recall od2": 0.4885594155360072,
        "f1_score od2": 0.5732564038865932,
        "iou od2": 0.40179357065151816,
        "accuracy is": 0.7155630116986227,
        "precision is": 0.7142857142857143,
        "recall is": 0.8318796992481203,
        "f1_score is": 0.7686108872648457,
        "iou is": 0.6241819740939658,
        "accuracy gpt1": 0.6106498920865537,
        "precision gpt1": 0.7673913043478261,
        "recall gpt1": 0.45112781954887216,
        "f1_score gpt1": 0.568216877489973,
        "iou gpt1": 0.3968596001424048,
        "accuracy gpt2": 0.7836048006775168,
        "precision gpt2": 0.8469289827255279,
        "recall gpt2": 0.7554887218045113,
        "f1_score gpt2": 0.7985998816783659,
        "iou gpt2": 0.664724324144413,
        "category": "other",
        "size10000": 2066.8416,
        "aspect ratio": 1.5
    },
    "4": {
        "accuracy od1": 0.7693754317734053,
        "precision od1": 0.9902912621359223,
        "recall od1": 0.7446231858716559,
        "f1_score od1": 0.8500636275170298,
        "iou od1": 0.7392266631948965,
        "accuracy od2": 0.12202236266407389,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.4512064068776706,
        "precision is": 0.9270138404859106,
        "recall is": 0.4069767441860465,
        "f1_score is": 0.5656307907287584,
        "iou is": 0.3943411410902622,
        "accuracy gpt1": 0.778744381615195,
        "precision gpt1": 1.0,
        "recall gpt1": 0.7479940160478716,
        "f1_score gpt1": 0.8558313234264374,
        "iou gpt1": 0.7479940160478716,
        "accuracy gpt2": 0.734385794335133,
        "precision gpt2": 1.0,
        "recall gpt2": 0.6974704202366381,
        "f1_score gpt2": 0.8217762288186516,
        "iou gpt2": 0.6974704202366381,
        "category": "none",
        "size10000": 23.4498,
        "aspect ratio": 1.7796143250688705
    },
    "91": {
        "accuracy od1": 0.8847274562584119,
        "precision od1": 0.9081632653061225,
        "recall od1": 0.9453510453076279,
        "f1_score od1": 0.9263840988450175,
        "iou od1": 0.8628636161670342,
        "accuracy od2": 0.8847274562584119,
        "precision od2": 0.9081632653061225,
        "recall od2": 0.9453510453076279,
        "f1_score od2": 0.9263840988450175,
        "iou od2": 0.8628636161670342,
        "accuracy is": 0.8494537909376402,
        "precision is": 0.8697081764389457,
        "recall is": 0.9454109818333852,
        "f1_score is": 0.9059809183858588,
        "iou is": 0.8281216786906069,
        "accuracy gpt1": 0.7638391655450875,
        "precision gpt1": 0.9844444444444445,
        "recall gpt1": 0.7033010407027485,
        "f1_score gpt1": 0.8204564116863085,
        "iou gpt1": 0.6955710834385153,
        "accuracy gpt2": 0.9668988335576492,
        "precision gpt2": 0.9627060653188181,
        "recall gpt2": 0.995417048579285,
        "f1_score gpt2": 0.978788333978986,
        "iou gpt2": 0.9584578462491291,
        "category": "single-person",
        "size10000": 89.16,
        "aspect ratio": 0.6191666666666666
    },
    "30": {
        "accuracy od1": 0.3562314915131817,
        "precision od1": 0.6787502473025004,
        "recall od1": 0.3960193836393382,
        "f1_score od1": 0.5001969665745619,
        "iou od1": 0.3335084377260856,
        "accuracy od2": 0.18656013001083424,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.18656013001083424,
        "precision is": 0,
        "recall is": 0.0,
        "f1_score is": 0,
        "iou is": 0.0,
        "accuracy gpt1": 0.7788317081979054,
        "precision gpt1": 0.9373333333333334,
        "recall gpt1": 0.7802736174284046,
        "f1_score gpt1": 0.851622625783935,
        "iou gpt1": 0.7415877784646285,
        "accuracy gpt2": 0.8032087396171903,
        "precision gpt2": 0.9149453219927096,
        "recall gpt2": 0.8357696072881774,
        "f1_score gpt2": 0.8735671121124199,
        "iou gpt2": 0.7755163414578883,
        "category": "none",
        "size10000": 110.76,
        "aspect ratio": 1.3001083423618636
    },
    "78": {
        "accuracy od1": 0.6993385905119704,
        "precision od1": 0.5910318841998538,
        "recall od1": 0.8431781756571115,
        "f1_score od1": 0.6949403017358812,
        "iou od1": 0.5324969445154368,
        "accuracy od2": 0.46112260602312727,
        "precision od2": 0.014570586054547866,
        "recall od2": 0.00490429526513417,
        "f1_score od2": 0.007338525460006836,
        "iou od2": 0.0036827758019966424,
        "accuracy is": 0.8295543099720557,
        "precision is": 0.9892638902762637,
        "recall is": 0.5867098063009433,
        "f1_score is": 0.7365742546402582,
        "iou is": 0.5829976611965664,
        "accuracy gpt1": 0.8023815391196396,
        "precision gpt1": 0.8136363636363636,
        "recall gpt1": 0.6659836065573771,
        "f1_score gpt1": 0.7324427769244328,
        "iou gpt1": 0.5778380364929427,
        "accuracy gpt2": 0.593845753262876,
        "precision gpt2": 0,
        "recall gpt2": 0.0,
        "f1_score gpt2": 0,
        "iou gpt2": 0.0,
        "category": "pair",
        "size10000": 860.284,
        "aspect ratio": 1.4997912317327766
    },
    "19": {
        "accuracy od1": 0.5594665,
        "precision od1": 0.5984077901211693,
        "recall od1": 0.7856173677069199,
        "f1_score od1": 0.6793511667490975,
        "iou od1": 0.5144071229569861,
        "accuracy od2": 0.522085,
        "precision od2": 0.580302072512342,
        "recall od2": 0.7062415196743554,
        "f1_score od2": 0.6371077047839685,
        "iou od2": 0.4674673905049708,
        "accuracy is": 0.45759916666666667,
        "precision is": 0.6601101494885917,
        "recall is": 0.17914011041117445,
        "f1_score is": 0.28180439307113553,
        "iou is": 0.16401182259733402,
        "accuracy gpt1": 0.7277166666666667,
        "precision gpt1": 0.8093641025641025,
        "recall gpt1": 0.7085079901642252,
        "f1_score gpt1": 0.7555853175849907,
        "iou gpt1": 0.6071812943565102,
        "accuracy gpt2": 0.7597833333333334,
        "precision gpt2": 0.815897619047619,
        "recall gpt2": 0.7691679208289705,
        "f1_score gpt2": 0.7918439452049731,
        "iou gpt2": 0.6554152851879018,
        "category": "group",
        "size10000": 600.0,
        "aspect ratio": 1.5
    },
    "22": {
        "accuracy od1": 0.9439164067411305,
        "precision od1": 0.9348387096774193,
        "recall od1": 0.9959083469721768,
        "f1_score od1": 0.9644077103046517,
        "iou od1": 0.9312619646756566,
        "accuracy od2": 0.9408933855037169,
        "precision od2": 0.936046511627907,
        "recall od2": 0.9901800327332242,
        "f1_score od2": 0.9623526040971986,
        "iou od2": 0.9274370155961381,
        "accuracy is": 0.951441213310428,
        "precision is": 0.9415204678362573,
        "recall is": 0.9983633387888707,
        "f1_score is": 0.9691090926135159,
        "iou is": 0.9400694929693407,
        "accuracy gpt1": 0.8701975175549377,
        "precision gpt1": 0.9211697393515575,
        "recall gpt1": 0.9075286415711947,
        "f1_score gpt1": 0.9142983128670734,
        "iou gpt1": 0.84212663911531,
        "accuracy gpt2": 0.9221503091314975,
        "precision gpt2": 0.9211697393515575,
        "recall gpt2": 0.9819967266775778,
        "f1_score gpt2": 0.9506111891988526,
        "iou gpt2": 0.9058712837552709,
        "category": "group",
        "size10000": 232.0857,
        "aspect ratio": 1.3544690603514133
    },
    "36": {
        "accuracy od1": 0.26199380435188296,
        "precision od1": 0.0,
        "recall od1": 0.0,
        "f1_score od1": 0,
        "iou od1": 0.0,
        "accuracy od2": 0.2667811244230458,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.5247465133928017,
        "precision is": 1.0,
        "recall is": 0.35182589750811905,
        "f1_score is": 0.5205195405068884,
        "iou is": 0.35182589750811905,
        "accuracy gpt1": 0.7878127371577153,
        "precision gpt1": 0.7982905982905983,
        "recall gpt1": 0.9508716323296355,
        "f1_score gpt1": 0.8679262231735063,
        "iou gpt1": 0.7666693116119482,
        "accuracy gpt2": 0.849552743875888,
        "precision gpt2": 0.8728971962616823,
        "recall gpt2": 0.93026941362916,
        "f1_score gpt2": 0.9006705852589524,
        "iou gpt2": 0.8192908996900712,
        "category": "none",
        "size10000": 80.379,
        "aspect ratio": 1.703056768558952
    },
    "73": {
        "accuracy od1": 0.8501410789959706,
        "precision od1": 0.9073110639653081,
        "recall od1": 0.9000904159132007,
        "f1_score od1": 0.9036863165366864,
        "iou od1": 0.8242953911529163,
        "accuracy od2": 0.7368119247093682,
        "precision od2": 0.9099248379832794,
        "recall od2": 0.735893979734346,
        "f1_score od2": 0.8137082928863811,
        "iou od2": 0.6859259725133077,
        "accuracy is": 0.7551175754749894,
        "precision is": 0.9123730823872893,
        "recall is": 0.7594195811708397,
        "f1_score is": 0.8288994194093875,
        "iou is": 0.7077952424815251,
        "accuracy gpt1": 0.8164956192346929,
        "precision gpt1": 0.9617956064947469,
        "recall gpt1": 0.796710522485964,
        "f1_score gpt1": 0.8715041335901306,
        "iou gpt1": 0.7722705590076131,
        "accuracy gpt2": 0.8258602387884981,
        "precision gpt2": 0.9181818181818182,
        "recall gpt2": 0.8530689812293707,
        "f1_score gpt2": 0.884428595295568,
        "iou gpt2": 0.7928032141787422,
        "category": "group",
        "size10000": 967.6848,
        "aspect ratio": 1.3333333333333333
    },
    "33": {
        "accuracy od1": 0.6419189982430153,
        "precision od1": 0.991747936984246,
        "recall od1": 0.4612453032742888,
        "f1_score od1": 0.6296506622213266,
        "iou od1": 0.4594818597438708,
        "accuracy od2": 0.6419189982430153,
        "precision od2": 0.991747936984246,
        "recall od2": 0.4612453032742888,
        "f1_score od2": 0.6296506622213266,
        "iou od2": 0.4594818597438708,
        "accuracy is": 0.614656911767286,
        "precision is": 0.9864559819413092,
        "recall is": 0.42189028651292804,
        "f1_score is": 0.5910140228658317,
        "iou is": 0.4194605428706502,
        "accuracy gpt1": 0.7009767431368569,
        "precision gpt1": 1.0,
        "recall gpt1": 0.5468963631391851,
        "f1_score gpt1": 0.707088562842496,
        "iou gpt1": 0.5468963631391851,
        "accuracy gpt2": 0.7977103222642462,
        "precision gpt2": 0.9027823529411765,
        "recall gpt2": 0.7771650512968533,
        "f1_score gpt2": 0.8352772138740278,
        "iou gpt2": 0.717146795635616,
        "category": "pair",
        "size10000": 598.4685,
        "aspect ratio": 1.3429654192325913
    },
    "1": {
        "accuracy od1": 0.48479112206784686,
        "precision od1": 0.8345905226190216,
        "recall od1": 0.4143807412100095,
        "f1_score od1": 0.553796951756066,
        "iou od1": 0.38293167230460434,
        "accuracy od2": 0.23963412466538692,
        "precision od2": 1.0,
        "recall od2": 0.014513202983269502,
        "f1_score od2": 0.02861116630240413,
        "iou od2": 0.014513202983269502,
        "accuracy is": 0.4070001926247059,
        "precision is": 1.0,
        "recall is": 0.23143120994923191,
        "f1_score is": 0.3758735495404134,
        "iou is": 0.23143120994923191,
        "accuracy gpt1": 0.682184012810783,
        "precision gpt1": 1.0,
        "recall gpt1": 0.5880884855360181,
        "f1_score gpt1": 0.7406243303093079,
        "iou gpt1": 0.5880884855360181,
        "accuracy gpt2": 0.8037525235489903,
        "precision gpt2": 0.9761222540592168,
        "recall gpt2": 0.7643470230589294,
        "f1_score gpt2": 0.8573505419953333,
        "iou gpt2": 0.750318075232336,
        "category": "other",
        "size10000": 967.6848,
        "aspect ratio": 1.3333333333333333
    },
    "85": {
        "accuracy od1": 0.23831106988556605,
        "precision od1": 0,
        "recall od1": 0.0,
        "f1_score od1": 0,
        "iou od1": 0.0,
        "accuracy od2": 0.23831106988556605,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.20442441588418048,
        "precision is": 0.0,
        "recall is": 0.0,
        "f1_score is": 0,
        "iou is": 0.0,
        "accuracy gpt1": 0.6853574635046453,
        "precision gpt1": 0.8551724137931035,
        "recall gpt1": 0.7065768630266562,
        "f1_score gpt1": 0.7738054378553109,
        "iou gpt1": 0.6310625260822214,
        "accuracy gpt2": 0.6203660530784404,
        "precision gpt2": 0.8057644110275689,
        "recall gpt2": 0.6609055146099148,
        "f1_score gpt2": 0.7261813083036607,
        "iou gpt2": 0.570082157717915,
        "category": "none",
        "size10000": 967.6848,
        "aspect ratio": 1.3333333333333333
    },
    "80": {
        "accuracy od1": 0.8966109045848822,
        "precision od1": 0.8942128886108904,
        "recall od1": 1.0,
        "f1_score od1": 0.9441524698595585,
        "iou od1": 0.8942128886108904,
        "accuracy od2": 0.5674483684427922,
        "precision od2": 0.9441566133607656,
        "recall od2": 0.5368073295633125,
        "f1_score od2": 0.6844598651159953,
        "iou od2": 0.5202880907744759,
        "accuracy is": 0.46567327550598925,
        "precision is": 0.9254820380662588,
        "recall is": 0.4226314682521865,
        "f1_score is": 0.5802743326222208,
        "iou is": 0.40872285819413434,
        "accuracy gpt1": 0.7867967781908303,
        "precision gpt1": 0.9101666666666667,
        "recall gpt1": 0.8388375165125496,
        "f1_score gpt1": 0.8730475931639782,
        "iou gpt1": 0.774697838052545,
        "accuracy gpt2": 0.7831206113176373,
        "precision gpt2": 1.0,
        "recall gpt2": 0.7518379442437075,
        "f1_score gpt2": 0.8583418879744453,
        "iou gpt2": 0.7518379442437075,
        "category": "single-person",
        "size10000": 96.84,
        "aspect ratio": 1.486988847583643
    },
    "67": {
        "accuracy od1": 0.897169395465995,
        "precision od1": 1.0,
        "recall od1": 0.7591519174041298,
        "f1_score od1": 0.8630885256622551,
        "iou od1": 0.7591519174041298,
        "accuracy od2": 0.8180604534005038,
        "precision od2": 1.0,
        "recall od2": 0.5738643067846607,
        "f1_score od2": 0.7292424185628069,
        "iou od2": 0.5738643067846607,
        "accuracy is": 0.5920340050377834,
        "precision is": 1.0,
        "recall is": 0.04446902654867257,
        "f1_score is": 0.08515145096377887,
        "iou is": 0.04446902654867257,
        "accuracy gpt1": 0.7514693534844669,
        "precision gpt1": 0.6545454545454545,
        "recall gpt1": 0.8849557522123894,
        "f1_score gpt1": 0.7525083612040133,
        "iou gpt1": 0.6032171581769437,
        "accuracy gpt2": 0.7052896725440806,
        "precision gpt2": 0.6060606060606061,
        "recall gpt2": 0.8849557522123894,
        "f1_score gpt2": 0.7194244604316549,
        "iou gpt2": 0.5617977528089888,
        "category": "group",
        "size10000": 95.28,
        "aspect ratio": 1.5113350125944585
    },
    "17": {
        "accuracy od1": 0.8597832745279745,
        "precision od1": 0.8585324689449438,
        "recall od1": 0.9800650935720098,
        "f1_score od1": 0.9152820841982122,
        "iou od1": 0.8437973328039535,
        "accuracy od2": 0.6083494566156386,
        "precision od2": 0.90754877014419,
        "recall od2": 0.5491826721620777,
        "f1_score od2": 0.6842854409953846,
        "iou od2": 0.5200865463653991,
        "accuracy is": 0.7428169170951533,
        "precision is": 0.8636639552990896,
        "recall is": 0.7922975193052547,
        "f1_score is": 0.8264429091991122,
        "iou is": 0.7042204556363856,
        "accuracy gpt1": 0.8897116086204705,
        "precision gpt1": 1.0,
        "recall gpt1": 0.8572963109947389,
        "f1_score gpt1": 0.9231659007986555,
        "iou gpt1": 0.8572963109947389,
        "accuracy gpt2": 0.7718533897445929,
        "precision gpt2": 1.0,
        "recall gpt2": 0.7047979165327178,
        "f1_score gpt2": 0.8268404245427076,
        "iou gpt2": 0.7047979165327178,
        "category": "pair",
        "size10000": 1400.666,
        "aspect ratio": 1.5932546374367622
    },
    "41": {
        "accuracy od1": 0.96356796875,
        "precision od1": 0.9849775334636255,
        "recall od1": 0.9481961147086031,
        "f1_score od1": 0.9662369142973812,
        "iou od1": 0.9346792583918376,
        "accuracy od2": 0.6896893229166666,
        "precision od2": 0.9922680301998621,
        "recall od2": 0.4390039186374718,
        "f1_score od2": 0.6087027052410042,
        "iou od2": 0.43750728728790156,
        "accuracy is": 0.9680268229166666,
        "precision is": 0.9902096909070828,
        "recall is": 0.951249838361533,
        "f1_score is": 0.9703388550924174,
        "iou is": 0.9423865898907064,
        "accuracy gpt1": 0.7817747395833333,
        "precision gpt1": 0.7273585714285714,
        "recall gpt1": 0.9646697388632872,
        "f1_score gpt1": 0.8293724152156106,
        "iou gpt1": 0.7084852825917026,
        "accuracy gpt2": 0.78034140625,
        "precision gpt2": 0.73476,
        "recall gpt2": 0.9396829186152095,
        "f1_score gpt2": 0.8246819447899928,
        "iou gpt2": 0.7016670433456735,
        "category": "pair",
        "size10000": 384.0,
        "aspect ratio": 1.5
    },
    "97": {
        "accuracy od1": 0.28932422316351347,
        "precision od1": 0.16120277255291104,
        "recall od1": 0.015149031999228926,
        "f1_score od1": 0.027695389519492596,
        "iou od1": 0.014042146112889347,
        "accuracy od2": 0.3318687782174259,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.7032535767258254,
        "precision is": 1.0,
        "recall is": 0.5558560749751297,
        "f1_score is": 0.7145340548083987,
        "iou is": 0.5558560749751297,
        "accuracy gpt1": 0.6088528904408311,
        "precision gpt1": 0.9392350230414747,
        "recall gpt1": 0.44324149687203473,
        "f1_score gpt1": 0.6022640262325588,
        "iou gpt1": 0.4308854014891121,
        "accuracy gpt2": 0.7203683899735436,
        "precision gpt2": 0.8780769230769231,
        "recall gpt2": 0.6752292083998367,
        "f1_score gpt2": 0.7634080284222016,
        "iou gpt2": 0.6173483622476946,
        "category": "none",
        "size10000": 860.284,
        "aspect ratio": 1.4997912317327766
    },
    "79": {
        "accuracy od1": 0.9398373557187828,
        "precision od1": 0.9274187433219592,
        "recall od1": 0.9930761622156281,
        "f1_score od1": 0.9591251127294245,
        "iou od1": 0.921460517934563,
        "accuracy od2": 0.9398373557187828,
        "precision od2": 0.9274187433219592,
        "recall od2": 0.9930761622156281,
        "f1_score od2": 0.9591251127294245,
        "iou od2": 0.921460517934563,
        "accuracy is": 0.9463588667366212,
        "precision is": 0.9411764705882353,
        "recall is": 0.9861670874116066,
        "f1_score is": 0.9631466635907491,
        "iou is": 0.9289131160307041,
        "accuracy gpt1": 0.9411927247289262,
        "precision gpt1": 0.9385835294117647,
        "recall gpt1": 0.9814872226405067,
        "f1_score gpt1": 0.9595560377281332,
        "iou gpt1": 0.9222563372205935,
        "accuracy gpt2": 0.8794648478488982,
        "precision gpt2": 1.0,
        "recall gpt2": 0.8304176447141148,
        "f1_score gpt2": 0.907353190253817,
        "iou gpt2": 0.8304176447141148,
        "category": "group",
        "size10000": 114.36,
        "aspect ratio": 1.2591815320041972
    },
    "8": {
        "accuracy od1": 0.40237503001424363,
        "precision od1": 1.0,
        "recall od1": 0.0064721407283677415,
        "f1_score od1": 0.012861042976676847,
        "iou od1": 0.0064721407283677415,
        "accuracy od2": 0.39848192035210495,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.6003268347153484,
        "precision is": 0.9540229885057471,
        "recall is": 0.35254951962763875,
        "f1_score is": 0.5148437522107866,
        "iou is": 0.34665965481893046,
        "accuracy gpt1": 0.7662632907733301,
        "precision gpt1": 0.7516639388979814,
        "recall gpt1": 0.913090389064795,
        "f1_score gpt1": 0.8245506341518045,
        "iou gpt1": 0.701476948398211,
        "accuracy gpt2": 0.7694080841471176,
        "precision gpt2": 0.7705093505610336,
        "recall gpt2": 0.8782222153323851,
        "f1_score gpt2": 0.8208473019892091,
        "iou gpt2": 0.6961331669545119,
        "category": "none",
        "size10000": 214.4815,
        "aspect ratio": 1.9270142180094787
    },
    "66": {
        "accuracy od1": 0.8080933333333333,
        "precision od1": 0.8592121533298004,
        "recall od1": 0.8584202682563339,
        "f1_score od1": 0.8588160282505273,
        "iou od1": 0.752565799652736,
        "accuracy od2": 0.5411133333333333,
        "precision od2": 0.8107044470680834,
        "recall od2": 0.4241509137971606,
        "f1_score od2": 0.5569251961661507,
        "iou od2": 0.3859295406492823,
        "accuracy is": 0.5439346666666667,
        "precision is": 0.7995116086590465,
        "recall is": 0.43946485998901874,
        "f1_score is": 0.5671734145884687,
        "iou is": 0.39584233037214844,
        "accuracy gpt1": 0.7093866666666667,
        "precision gpt1": 0.9171428571428571,
        "recall gpt1": 0.6294611342066044,
        "f1_score gpt1": 0.7465463509930694,
        "iou gpt1": 0.5955915095739943,
        "accuracy gpt2": 0.7328533333333334,
        "precision gpt2": 0.93,
        "recall gpt2": 0.6565220801631501,
        "f1_score gpt2": 0.7696905604855395,
        "iou gpt2": 0.6256072950145751,
        "category": "single-person",
        "size10000": 150.0,
        "aspect ratio": 1.5
    },
    "44": {
        "accuracy od1": 0.5291159766319533,
        "precision od1": 0.7555555555555555,
        "recall od1": 0.0032500245431106196,
        "f1_score od1": 0.006472208859929155,
        "iou od1": 0.003246610801561883,
        "accuracy od2": 0.5280784353568707,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.918250444500889,
        "precision is": 0.9508362899138368,
        "recall is": 0.8718528125256555,
        "f1_score is": 0.9096332364124157,
        "iou is": 0.8342451978447055,
        "accuracy gpt1": 0.7825937177207688,
        "precision gpt1": 0.927,
        "recall gpt1": 0.5854177754124534,
        "f1_score gpt1": 0.7176354134813693,
        "iou gpt1": 0.5596188642651222,
        "accuracy gpt2": 0.7576722716112099,
        "precision gpt2": 0.6955106560922855,
        "recall gpt2": 0.8653539116551358,
        "f1_score gpt2": 0.7711916578590468,
        "iou gpt2": 0.6275931171783871,
        "category": "none",
        "size10000": 738.1875,
        "aspect ratio": 1.3655913978494623
    },
    "98": {
        "accuracy od1": 0.39003561160156885,
        "precision od1": 0,
        "recall od1": 0.0,
        "f1_score od1": 0,
        "iou od1": 0.0,
        "accuracy od2": 0.39003561160156885,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.488555716204794,
        "precision is": 1.0,
        "recall is": 0.16151779755848866,
        "f1_score is": 0.2781150627187964,
        "iou is": 0.16151779755848866,
        "accuracy gpt1": 0.7054454122581492,
        "precision gpt1": 0.8028698412698413,
        "recall gpt1": 0.6853774676800674,
        "f1_score gpt1": 0.7394858305834737,
        "iou gpt1": 0.5866541198230013,
        "accuracy gpt2": 0.6632933540805948,
        "precision gpt2": 0.7461161290322581,
        "recall gpt2": 0.6790540639725203,
        "f1_score gpt2": 0.7110072777295329,
        "iou gpt2": 0.5515991405111621,
        "category": "none",
        "size10000": 725.9432,
        "aspect ratio": 1.7773379515091539
    },
    "75": {
        "accuracy od1": 0.42163228212268844,
        "precision od1": 0.3769230769230769,
        "recall od1": 0.0015067650676506765,
        "f1_score od1": 0.003001531393568147,
        "iou od1": 0.0015030213797122788,
        "accuracy od2": 0.42220084217958426,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.858556571476584,
        "precision is": 1.0,
        "recall is": 0.7552031244611511,
        "f1_score is": 0.8605307430648509,
        "iou is": 0.7552031244611511,
        "accuracy gpt1": 0.7356394997136443,
        "precision gpt1": 1.0,
        "recall gpt1": 0.5424699106804152,
        "f1_score gpt1": 0.7033782726317437,
        "iou gpt1": 0.5424699106804152,
        "accuracy gpt2": 0.8401462846576294,
        "precision gpt2": 0.9430494631226897,
        "recall gpt2": 0.7698302123208148,
        "f1_score gpt2": 0.8476812222514059,
        "iou gpt2": 0.7356308329085892,
        "category": "none",
        "size10000": 602.2231,
        "aspect ratio": 1.5660377358490567
    },
    "14": {
        "accuracy od1": 0.656279922202274,
        "precision od1": 0.7814103758931346,
        "recall od1": 0.6892039258451472,
        "f1_score od1": 0.7324165120998856,
        "iou od1": 0.577805343073071,
        "accuracy od2": 0.31746334530221426,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.48691576900059846,
        "precision is": 0.9056603773584906,
        "recall is": 0.27713704838258907,
        "f1_score is": 0.42440410903149417,
        "iou is": 0.2693610153874014,
        "accuracy gpt1": 0.8833669958108917,
        "precision gpt1": 0.9045454545454545,
        "recall gpt1": 0.9269356597600873,
        "f1_score gpt1": 0.9156036948925932,
        "iou gpt1": 0.8443441669620082,
        "accuracy gpt2": 0.8081874625972472,
        "precision gpt2": 0.9555555555555556,
        "recall gpt2": 0.7540428423469584,
        "f1_score gpt2": 0.8429229086966243,
        "iou gpt2": 0.7284933000852379,
        "category": "none",
        "size10000": 133.68,
        "aspect ratio": 0.9283333333333333
    },
    "51": {
        "accuracy od1": 0.8840966604001633,
        "precision od1": 0.9032027690480673,
        "recall od1": 0.9645980841316119,
        "f1_score od1": 0.9328913830647253,
        "iou od1": 0.8742234560376619,
        "accuracy od2": 0.9033472469547935,
        "precision od2": 0.9357953514329926,
        "recall od2": 0.9494098195864616,
        "f1_score od2": 0.9425534254114124,
        "iou od2": 0.8913485069239778,
        "accuracy is": 0.3052933145172891,
        "precision is": 0.9478458049886621,
        "recall is": 0.17797323010836988,
        "f1_score is": 0.29967725593476235,
        "iou is": 0.17624727833627357,
        "accuracy gpt1": 0.8809771528911067,
        "precision gpt1": 1.0,
        "recall gpt1": 0.8574858514834506,
        "f1_score gpt1": 0.9232757824762258,
        "iou gpt1": 0.8574858514834506,
        "accuracy gpt2": 0.7984329194795661,
        "precision gpt2": 0.9684300341296929,
        "recall gpt2": 0.7842147372245125,
        "f1_score gpt2": 0.8666412237643999,
        "iou gpt2": 0.7646662662664595,
        "category": "other",
        "size10000": 967.6848,
        "aspect ratio": 1.3333333333333333
    },
    "46": {
        "accuracy od1": 0.9638045363531597,
        "precision od1": 0.9739643075506415,
        "recall od1": 0.9760875828291559,
        "f1_score od1": 0.9750247892468362,
        "iou od1": 0.9512667028604296,
        "accuracy od2": 0.8849656417048196,
        "precision od2": 0.9877630934899657,
        "recall od2": 0.8516277729760876,
        "f1_score od2": 0.9146576715942992,
        "iou od2": 0.8427365704402902,
        "accuracy is": 0.6688890845448848,
        "precision is": 0.9909954977488744,
        "recall is": 0.547537732290686,
        "f1_score is": 0.7053567865202967,
        "iou is": 0.544827161009449,
        "accuracy gpt1": 0.5415368723369428,
        "precision gpt1": 0.8566666666666667,
        "recall gpt1": 0.4402897689163989,
        "f1_score gpt1": 0.5816410765338945,
        "iou gpt1": 0.4100803167032734,
        "accuracy gpt2": 0.5453397635263053,
        "precision gpt2": 0.8115789473684211,
        "recall gpt2": 0.4843187458080388,
        "f1_score gpt2": 0.6066264335268933,
        "iou gpt2": 0.43536525173387636,
        "category": "group",
        "size10000": 967.6848,
        "aspect ratio": 1.3333333333333333
    },
    "26": {
        "accuracy od1": 0.9114439833009329,
        "precision od1": 1.0,
        "recall od1": 0.8130562347188264,
        "f1_score od1": 0.8968902554144078,
        "iou od1": 0.8130562347188264,
        "accuracy od2": 0.5262959608956518,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.8569307597096544,
        "precision is": 0.8960893854748604,
        "recall is": 0.7895317617751534,
        "f1_score is": 0.839442519306558,
        "iou is": 0.7233097311173114,
        "accuracy gpt1": 0.8518158836939344,
        "precision gpt1": 0.7617190245273737,
        "recall gpt1": 1.0,
        "f1_score gpt1": 0.8647451879924205,
        "iou gpt1": 0.7617190245273737,
        "accuracy gpt2": 0.7357423322750731,
        "precision gpt2": 0.6419086989481664,
        "recall gpt2": 1.0,
        "f1_score gpt2": 0.7819054730136744,
        "iou gpt2": 0.6419086989481664,
        "category": "none",
        "size10000": 228.8032,
        "aspect ratio": 1.8046181172291296
    },
    "65": {
        "accuracy od1": 0.9739753111312744,
        "precision od1": 0.9960411718131433,
        "recall od1": 0.9603816473968176,
        "f1_score od1": 0.9778864283000415,
        "iou od1": 0.9567297171033945,
        "accuracy od2": 0.9739753111312744,
        "precision od2": 0.9960411718131433,
        "recall od2": 0.9603816473968176,
        "f1_score od2": 0.9778864283000415,
        "iou od2": 0.9567297171033945,
        "accuracy is": 0.9858996762666488,
        "precision is": 0.9960505529225908,
        "recall is": 0.9803536345776032,
        "f1_score is": 0.9881397600313446,
        "iou is": 0.9765575531082775,
        "accuracy gpt1": 0.8693967432499543,
        "precision gpt1": 0.9461688888888888,
        "recall gpt1": 0.8291981447349767,
        "f1_score gpt1": 0.8838301854362812,
        "iou gpt1": 0.7918420422270129,
        "accuracy gpt2": 0.7641927389633811,
        "precision gpt2": 0.7808369408369409,
        "recall gpt2": 0.8430643344462638,
        "f1_score gpt2": 0.8107583704224223,
        "iou gpt2": 0.6817440209441762,
        "category": "group",
        "size10000": 214.2504,
        "aspect ratio": 1.067043048694425
    },
    "43": {
        "accuracy od1": 0.8636515155578885,
        "precision od1": 0.8209959623149394,
        "recall od1": 0.8008528426337292,
        "f1_score od1": 0.8107993152068734,
        "iou od1": 0.6818019242462177,
        "accuracy od2": 0.8636515155578885,
        "precision od2": 0.8209959623149394,
        "recall od2": 0.8008528426337292,
        "f1_score od2": 0.8107993152068734,
        "iou od2": 0.6818019242462177,
        "accuracy is": 0.7276504222974052,
        "precision is": 1.0,
        "recall is": 0.2534336018597291,
        "f1_score is": 0.40438297087888453,
        "iou is": 0.2534336018597291,
        "accuracy gpt1": 0.7376391959426754,
        "precision gpt1": 0.5820982599795291,
        "recall gpt1": 0.9955257270693513,
        "f1_score gpt1": 0.734641205064246,
        "iou gpt1": 0.580579364528419,
        "accuracy gpt2": 0.6176564122409414,
        "precision gpt2": 0.48826153846153847,
        "recall gpt2": 1.0,
        "f1_score gpt2": 0.656150180385995,
        "iou gpt2": 0.48826153846153847,
        "category": "other",
        "size10000": 78.2979,
        "aspect ratio": 1.4814305364511693
    },
    "34": {
        "accuracy od1": 0.9646045503791982,
        "precision od1": 0.992430613961312,
        "recall od1": 0.9679715302491103,
        "f1_score od1": 0.9800484894379744,
        "iou od1": 0.9608775312249273,
        "accuracy od2": 0.9646045503791982,
        "precision od2": 0.992430613961312,
        "recall od2": 0.9679715302491103,
        "f1_score od2": 0.9800484894379744,
        "iou od2": 0.9608775312249273,
        "accuracy is": 0.8390231130371976,
        "precision is": 1.0,
        "recall is": 0.8207591933570582,
        "f1_score is": 0.9015571046973745,
        "iou is": 0.8207591933570582,
        "accuracy gpt1": 0.6300650054171181,
        "precision gpt1": 1.0,
        "recall gpt1": 0.5880933711321551,
        "f1_score gpt1": 0.7406282046412701,
        "iou gpt1": 0.5880933711321551,
        "accuracy gpt2": 0.7113217768147345,
        "precision gpt2": 1.0,
        "recall gpt2": 0.6785692743832559,
        "f1_score gpt2": 0.8085091092026303,
        "iou gpt2": 0.6785692743832559,
        "category": "animal",
        "size10000": 110.76,
        "aspect ratio": 1.3001083423618636
    },
    "63": {
        "accuracy od1": 0.5182621479034424,
        "precision od1": 0.3682387183631374,
        "recall od1": 0.8450312717164697,
        "f1_score od1": 0.5129496897112368,
        "iou od1": 0.3449444085127352,
        "accuracy od2": 0.5223104953765869,
        "precision od2": 0.37041549896429876,
        "recall od2": 0.8450312717164697,
        "f1_score od2": 0.51505781693422,
        "iou od2": 0.34685378515602716,
        "accuracy is": 0.8462207317352295,
        "precision is": 1.0,
        "recall is": 0.4877418842450114,
        "f1_score is": 0.6556807863112991,
        "iou is": 0.4877418842450114,
        "accuracy gpt1": 0.8489034175872803,
        "precision gpt1": 0.917588141025641,
        "recall gpt1": 0.5456884741387868,
        "f1_score gpt1": 0.6843781515743865,
        "iou gpt1": 0.5201936653707693,
        "accuracy gpt2": 0.5931675434112549,
        "precision gpt2": 0.424590558636913,
        "recall gpt2": 1.0,
        "f1_score gpt2": 0.5960878458203075,
        "iou gpt2": 0.424590558636913,
        "category": "group",
        "size10000": 419.4304,
        "aspect ratio": 1.0
    },
    "2": {
        "accuracy od1": 0.4361543655395508,
        "precision od1": 0.7942857142857143,
        "recall od1": 0.050176419498425794,
        "f1_score od1": 0.09439005399333698,
        "iou od1": 0.04953272530463952,
        "accuracy od2": 0.4361543655395508,
        "precision od2": 0.7942857142857143,
        "recall od2": 0.050176419498425794,
        "f1_score od2": 0.09439005399333698,
        "iou od2": 0.04953272530463952,
        "accuracy is": 0.43694814046223956,
        "precision is": 0.7931034482758621,
        "recall is": 0.052137661491694715,
        "f1_score is": 0.09784322753888344,
        "iou is": 0.05143804598833797,
        "accuracy gpt1": 0.7276128133138021,
        "precision gpt1": 0.7932571428571429,
        "recall gpt1": 0.7234133101726197,
        "f1_score gpt1": 0.7567270455965022,
        "iou gpt1": 0.608657208311563,
        "accuracy gpt2": 0.7897923787434896,
        "precision gpt2": 0.8399769691386458,
        "recall gpt2": 0.7919183584844208,
        "f1_score gpt2": 0.8152400111763063,
        "iou gpt2": 0.6881056238113925,
        "category": "single-person",
        "size10000": 314.5728,
        "aspect ratio": 0.75
    },
    "18": {
        "accuracy od1": 0.3790809151126714,
        "precision od1": 1.0,
        "recall od1": 0.14780529852065774,
        "f1_score od1": 0.2575441997195095,
        "iou od1": 0.14780529852065774,
        "accuracy od2": 0.27138823579932797,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.7358315351004326,
        "precision is": 0.9967105263157895,
        "recall is": 0.6395466199092356,
        "f1_score is": 0.7791475192072952,
        "iou is": 0.6381995625723685,
        "accuracy gpt1": 0.7395729331057361,
        "precision gpt1": 0.7505112474437627,
        "recall gpt1": 0.9625449401779925,
        "f1_score gpt1": 0.8434058485572267,
        "iou gpt1": 0.7292150383997142,
        "accuracy gpt2": 0.6873436610948286,
        "precision gpt2": 0.786046511627907,
        "recall gpt2": 0.7843902870277598,
        "f1_score gpt2": 0.7852175259784797,
        "iou gpt2": 0.6463852934748294,
        "category": "none",
        "size10000": 37.2588,
        "aspect ratio": 1.4381139489194499
    },
    "25": {
        "accuracy od1": 0.6016887448091379,
        "precision od1": 0,
        "recall od1": 0.0,
        "f1_score od1": 0,
        "iou od1": 0.0,
        "accuracy od2": 0.6016887448091379,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.5594226681450268,
        "precision is": 0.0,
        "recall is": 0.0,
        "f1_score is": 0,
        "iou is": 0.0,
        "accuracy gpt1": 0.7870581101539332,
        "precision gpt1": 0.7631964285714286,
        "recall gpt1": 0.6747481870520255,
        "f1_score gpt1": 0.7162520738949003,
        "iou gpt1": 0.5579382519962577,
        "accuracy gpt2": 0.7690329373376057,
        "precision gpt2": 0.6447247592886151,
        "recall gpt2": 0.935814098718394,
        "f1_score gpt2": 0.7634643292426199,
        "iou gpt2": 0.6174220018861217,
        "category": "none",
        "size10000": 3578.0184,
        "aspect ratio": 1.5
    },
    "56": {
        "accuracy od1": 0.2752794906502231,
        "precision od1": 0,
        "recall od1": 0.0,
        "f1_score od1": 0,
        "iou od1": 0.0,
        "accuracy od2": 0.2752794906502231,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.8385972827994185,
        "precision is": 1.0,
        "recall is": 0.7772897066961815,
        "f1_score is": 0.8746910577016639,
        "iou is": 0.7772897066961815,
        "accuracy gpt1": 0.8069383867248208,
        "precision gpt1": 0.8034682080924855,
        "recall gpt1": 0.9711538461538461,
        "f1_score gpt1": 0.8793886435528829,
        "iou gpt1": 0.7847400782560089,
        "accuracy gpt2": 0.7715947260239635,
        "precision gpt2": 0.8492063492063492,
        "recall gpt2": 0.8326992252351965,
        "f1_score gpt2": 0.840871782333834,
        "iou gpt2": 0.7254346581492753,
        "category": "none",
        "size10000": 39.894,
        "aspect ratio": 1.343119266055046
    },
    "84": {
        "accuracy od1": 0.9125507253657529,
        "precision od1": 0.9234449760765551,
        "recall od1": 0.9103097787294789,
        "f1_score od1": 0.916830333650603,
        "iou od1": 0.8464328000807047,
        "accuracy od2": 0.9125507253657529,
        "precision od2": 0.9234449760765551,
        "recall od2": 0.9103097787294789,
        "f1_score od2": 0.916830333650603,
        "iou od2": 0.8464328000807047,
        "accuracy is": 0.6465928183487673,
        "precision is": 1.0,
        "recall is": 0.33255674518201284,
        "f1_score is": 0.49912582917673676,
        "iou is": 0.33255674518201284,
        "accuracy gpt1": 0.8151873280082166,
        "precision gpt1": 0.9049180327868852,
        "recall gpt1": 0.72739252182507,
        "f1_score gpt1": 0.8065016893434389,
        "iou gpt1": 0.6757459831675593,
        "accuracy gpt2": 0.8224554054028911,
        "precision gpt2": 0.7488898026315789,
        "recall gpt2": 1.0,
        "f1_score gpt2": 0.856417370042085,
        "iou gpt2": 0.7488898026315789,
        "category": "other",
        "size10000": 859.9248,
        "aspect ratio": 1.5004177109440267
    },
    "15": {
        "accuracy od1": 0.6988445937788695,
        "precision od1": 0.6452326739303871,
        "recall od1": 0.9789029535864979,
        "f1_score od1": 0.7777923956100189,
        "iou od1": 0.6363832075797178,
        "accuracy od2": 0.9167929710464433,
        "precision od2": 0.933288409703504,
        "recall od2": 0.9105485232067511,
        "f1_score od2": 0.921778241897127,
        "iou od2": 0.8549059921764073,
        "accuracy is": 0.6449118034559502,
        "precision is": 1.0,
        "recall is": 0.34050663376441376,
        "f1_score is": 0.5080267791114204,
        "iou is": 0.34050663376441376,
        "accuracy gpt1": 0.7500387114722432,
        "precision gpt1": 0.6989355203619909,
        "recall gpt1": 0.9411552346570398,
        "f1_score gpt1": 0.8021590532882394,
        "iou gpt1": 0.6696707567814218,
        "accuracy gpt2": 0.7866167879188712,
        "precision gpt2": 0.7596153846153846,
        "recall gpt2": 0.8831768953068592,
        "f1_score gpt2": 0.8167493422159189,
        "iou gpt2": 0.6902589378192078,
        "category": "group",
        "size10000": 1219.2768,
        "aspect ratio": 1.3333333333333333
    },
    "55": {
        "accuracy od1": 0.914379073962718,
        "precision od1": 0.9063675142346336,
        "recall od1": 0.9691288518560223,
        "f1_score od1": 0.9366980649082727,
        "iou od1": 0.8809332833833947,
        "accuracy od2": 0.9535247143716176,
        "precision od2": 0.9884643114635905,
        "recall od2": 0.9398683243142996,
        "f1_score od2": 0.9635539831902531,
        "iou od2": 0.9296711720270191,
        "accuracy is": 0.9720779314491882,
        "precision is": 0.9914224446032881,
        "recall is": 0.9656378859767455,
        "f1_score is": 0.9783603076077632,
        "iou is": 0.9576373303555463,
        "accuracy gpt1": 0.8571098015634395,
        "precision gpt1": 0.8889230769230769,
        "recall gpt1": 0.892983699503898,
        "f1_score gpt1": 0.8909487615248296,
        "iou gpt1": 0.8033431915641616,
        "accuracy gpt2": 0.8300695129284426,
        "precision gpt2": 0.9043062200956937,
        "recall gpt2": 0.827609503434298,
        "f1_score gpt2": 0.8642596306482273,
        "iou gpt2": 0.7609658456901609,
        "category": "group",
        "size10000": 415.75,
        "aspect ratio": 1.503307276007216
    },
    "87": {
        "accuracy od1": 0.9500998663994656,
        "precision od1": 0.9848637739656912,
        "recall od1": 0.9405821824672788,
        "f1_score od1": 0.962213782064009,
        "iou od1": 0.927179187229635,
        "accuracy od2": 0.8842999331997328,
        "precision od2": 0.9848637739656912,
        "recall od2": 0.8416497312585605,
        "f1_score od2": 0.9076421590244367,
        "iou od2": 0.8309018574113397,
        "accuracy is": 0.8789642618570475,
        "precision is": 0.991374936580416,
        "recall is": 0.8280193236714976,
        "f1_score is": 0.9023636299462998,
        "iou is": 0.8220970574272727,
        "accuracy gpt1": 0.6986005344021377,
        "precision gpt1": 1.0,
        "recall gpt1": 0.5538002066861486,
        "f1_score gpt1": 0.712833225665815,
        "iou gpt1": 0.5538002066861486,
        "accuracy gpt2": 0.8428891115564462,
        "precision gpt2": 0.985,
        "recall gpt2": 0.7792760051226519,
        "f1_score gpt2": 0.870143744875621,
        "iou gpt2": 0.770136679714033,
        "category": "pair",
        "size10000": 598.8,
        "aspect ratio": 1.503006012024048
    },
    "54": {
        "accuracy od1": 0.550189683510435,
        "precision od1": 1.0,
        "recall od1": 0.1383337528316134,
        "f1_score od1": 0.2430460354663247,
        "iou od1": 0.1383337528316134,
        "accuracy od2": 0.4779761677241801,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.495512734755243,
        "precision is": 1.0,
        "recall is": 0.03359342226696871,
        "f1_score is": 0.06500316573859118,
        "iou is": 0.03359342226696871,
        "accuracy gpt1": 0.8558301799046963,
        "precision gpt1": 0.9219653179190751,
        "recall gpt1": 0.7907542579075426,
        "f1_score gpt1": 0.8513337630717813,
        "iou gpt1": 0.7411498098424408,
        "accuracy gpt2": 0.8369892401192569,
        "precision gpt2": 0.7620401046207498,
        "recall gpt2": 1.0,
        "f1_score gpt2": 0.8649520548623001,
        "iou gpt2": 0.7620401046207498,
        "category": "none",
        "size10000": 251.1552,
        "aspect ratio": 1.6440129449838188
    },
    "39": {
        "accuracy od1": 0.4960486649440138,
        "precision od1": 1.0,
        "recall od1": 0.3510204647551439,
        "f1_score od1": 0.5196375242454409,
        "iou od1": 0.3510204647551439,
        "accuracy od2": 0.4960486649440138,
        "precision od2": 1.0,
        "recall od2": 0.3510204647551439,
        "f1_score od2": 0.5196375242454409,
        "iou od2": 0.3510204647551439,
        "accuracy is": 0.580291774332472,
        "precision is": 1.0,
        "recall is": 0.4595072375353558,
        "f1_score is": 0.6296744897426032,
        "iou is": 0.4595072375353558,
        "accuracy gpt1": 0.8957364341085271,
        "precision gpt1": 0.946,
        "recall gpt1": 0.9181409794243248,
        "f1_score gpt1": 0.9318623174129634,
        "iou gpt1": 0.8724177908937606,
        "accuracy gpt2": 0.7747286821705426,
        "precision gpt2": 0.946,
        "recall gpt2": 0.7528756031279463,
        "f1_score gpt2": 0.8384608257929032,
        "iou gpt2": 0.7218532481827512,
        "category": "animal",
        "size10000": 92.88,
        "aspect ratio": 1.550387596899225
    },
    "28": {
        "accuracy od1": 0.9337412983626372,
        "precision od1": 0.9509892205738566,
        "recall od1": 0.9761799735333039,
        "f1_score od1": 0.9634199581530093,
        "iou od1": 0.9294216744096058,
        "accuracy od2": 0.9337412983626372,
        "precision od2": 0.9509892205738566,
        "recall od2": 0.9761799735333039,
        "f1_score od2": 0.9634199581530093,
        "iou od2": 0.9294216744096058,
        "accuracy is": 0.9304758527231555,
        "precision is": 0.9495415661329238,
        "recall is": 0.9739744155271284,
        "f1_score is": 0.9616028155844831,
        "iou is": 0.9260452840362245,
        "accuracy gpt1": 0.8266441244828449,
        "precision gpt1": 1.0,
        "recall gpt1": 0.8060525415827898,
        "f1_score gpt1": 0.8926125049234512,
        "iou gpt1": 0.8060525415827898,
        "accuracy gpt2": 0.7916696977836473,
        "precision gpt2": 1.0,
        "recall gpt2": 0.7669237774282854,
        "f1_score gpt2": 0.868089260244745,
        "iou gpt2": 0.7669237774282854,
        "category": "group",
        "size10000": 857.7696,
        "aspect ratio": 1.5041876046901173
    },
    "37": {
        "accuracy od1": 0.3857369323050557,
        "precision od1": 0.0,
        "recall od1": 0.0,
        "f1_score od1": 0,
        "iou od1": 0.0,
        "accuracy od2": 0.5700128534704371,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.5283097686375321,
        "precision is": 0.4100931074615285,
        "recall is": 0.22119341563786007,
        "f1_score is": 0.28738106026280014,
        "iou is": 0.16780210331371123,
        "accuracy gpt1": 0.6915295629820052,
        "precision gpt1": 0.59454,
        "recall gpt1": 0.8886198547215496,
        "f1_score gpt1": 0.7124249577606556,
        "iou gpt1": 0.5533075233592674,
        "accuracy gpt2": 0.787879177377892,
        "precision gpt2": 0.6883333333333334,
        "recall gpt2": 0.9259259259259259,
        "f1_score gpt2": 0.7896447554586823,
        "iou gpt2": 0.6524074308100594,
        "category": "none",
        "size10000": 93.36,
        "aspect ratio": 1.5424164524421593
    },
    "72": {
        "accuracy od1": 0.7746079424713298,
        "precision od1": 0.759106009053182,
        "recall od1": 1.0,
        "f1_score od1": 0.8630588550621368,
        "iou od1": 0.759106009053182,
        "accuracy od2": 0.9707577537277968,
        "precision od2": 0.9699963056953553,
        "recall od2": 0.9894335192251248,
        "f1_score od2": 0.9796185055195584,
        "iou od2": 0.9600512267407997,
        "accuracy is": 0.6708478664359303,
        "precision is": 1.0,
        "recall is": 0.5365727108325364,
        "f1_score is": 0.6984019787020868,
        "iou is": 0.5365727108325364,
        "accuracy gpt1": 0.5886250265257142,
        "precision gpt1": 1.0,
        "recall gpt1": 0.42080767721526313,
        "f1_score gpt1": 0.5923499485025764,
        "iou gpt1": 0.42080767721526313,
        "accuracy gpt2": 0.73373786915575,
        "precision gpt2": 0.9296987087517934,
        "recall gpt2": 0.6762547695920165,
        "f1_score gpt2": 0.7829780806917515,
        "iou gpt2": 0.6433557754956408,
        "category": "pair",
        "size10000": 1338.324,
        "aspect ratio": 1.5030160857908847
    },
    "16": {
        "accuracy od1": 0.8435294313823578,
        "precision od1": 1.0,
        "recall od1": 0.6969454061595701,
        "f1_score od1": 0.8214117008476509,
        "iou od1": 0.6969454061595701,
        "accuracy od2": 0.557514423878606,
        "precision od2": 1.0,
        "recall od2": 0.14298715894997932,
        "f1_score od2": 0.25019906449576634,
        "iou od2": 0.14298715894997932,
        "accuracy is": 0.5979289644822411,
        "precision is": 1.0,
        "recall is": 0.22126266019016122,
        "f1_score is": 0.3623506513426173,
        "iou is": 0.22126266019016122,
        "accuracy gpt1": 0.6971285642821411,
        "precision gpt1": 1.0,
        "recall gpt1": 0.41339396444811904,
        "f1_score gpt1": 0.584966364434045,
        "iou gpt1": 0.41339396444811904,
        "accuracy gpt2": 0.83906619976655,
        "precision gpt2": 0.944,
        "recall gpt2": 0.7317073170731707,
        "f1_score gpt2": 0.8244061481136469,
        "iou gpt2": 0.7012678288431062,
        "category": "other",
        "size10000": 599.7,
        "aspect ratio": 1.5007503751875937
    },
    "82": {
        "accuracy od1": 0.82713802148946,
        "precision od1": 0.8253929139663937,
        "recall od1": 0.9865168539325843,
        "f1_score od1": 0.8987909168220497,
        "iou od1": 0.8161855278456774,
        "accuracy od2": 0.8396451076572604,
        "precision od2": 0.8366454303395786,
        "recall od2": 0.9865168539325843,
        "f1_score od2": 0.9054211190258071,
        "iou od2": 0.8271867242861178,
        "accuracy is": 0.8241469041320232,
        "precision is": 0.8209420686674388,
        "recall is": 0.9898876404494382,
        "f1_score is": 0.8975337694180068,
        "iou is": 0.8141145229856134,
        "accuracy gpt1": 0.689446235670194,
        "precision gpt1": 1.0,
        "recall gpt1": 0.6008532115604158,
        "f1_score gpt1": 0.750666216266937,
        "iou gpt1": 0.6008532115604158,
        "accuracy gpt2": 0.6812446525678173,
        "precision gpt2": 1.0,
        "recall gpt2": 0.5903119271470751,
        "f1_score gpt2": 0.7423850844231038,
        "iou gpt2": 0.5903119271470751,
        "category": "pair",
        "size10000": 1219.2768,
        "aspect ratio": 1.3333333333333333
    },
    "99": {
        "accuracy od1": 0.6301025028280806,
        "precision od1": 0.6111648283615617,
        "recall od1": 0.9001795865709434,
        "f1_score od1": 0.7280380263896125,
        "iou od1": 0.5723740500850982,
        "accuracy od2": 0.5876577270219615,
        "precision od2": 1.0,
        "recall od2": 0.2502961447567391,
        "f1_score od2": 0.40037897550333945,
        "iou od2": 0.2502961447567391,
        "accuracy is": 0.8961871529912641,
        "precision is": 0.8838890886571577,
        "recall is": 0.9339371337240278,
        "f1_score is": 0.9082241545719192,
        "iou is": 0.8318778606205638,
        "accuracy gpt1": 0.7044507208122581,
        "precision gpt1": 0.7906896551724137,
        "recall gpt1": 0.6292073452342858,
        "f1_score gpt1": 0.7007659551259657,
        "iou gpt1": 0.5393685286271171,
        "accuracy gpt2": 0.6770132311447364,
        "precision gpt2": 0.6752705427490527,
        "recall gpt2": 0.7951243976842028,
        "f1_score gpt2": 0.7303127463414956,
        "iou gpt2": 0.5751910513688757,
        "category": "single-person",
        "size10000": 861.3616,
        "aspect ratio": 1.4979149291075897
    },
    "57": {
        "accuracy od1": 0.8303943048919893,
        "precision od1": 1.0,
        "recall od1": 0.6819846974263853,
        "f1_score od1": 0.8109285399205999,
        "iou od1": 0.6819846974263853,
        "accuracy od2": 0.7123034337720198,
        "precision od2": 1.0,
        "recall od2": 0.4605610943658706,
        "f1_score od2": 0.6306632377686764,
        "iou od2": 0.4605610943658706,
        "accuracy is": 0.7614743016677903,
        "precision is": 1.0,
        "recall is": 0.5527578122987351,
        "f1_score is": 0.7119691273430734,
        "iou is": 0.5527578122987351,
        "accuracy gpt1": 0.8777598044962922,
        "precision gpt1": 0.98,
        "recall gpt1": 0.7868545568522383,
        "f1_score gpt1": 0.8728703364118294,
        "iou gpt1": 0.7744187422351062,
        "accuracy gpt2": 0.7963396180789636,
        "precision gpt2": 0.7285142857142857,
        "recall gpt2": 0.9853157121879589,
        "f1_score gpt2": 0.8376753507014029,
        "iou gpt2": 0.7206896551724138,
        "category": "single-person",
        "size10000": 109.1744,
        "aspect ratio": 1.4357798165137614
    },
    "62": {
        "accuracy od1": 0.8958108333199005,
        "precision od1": 0.9128484883028524,
        "recall od1": 0.969017094017094,
        "f1_score od1": 0.9400945505604527,
        "iou od1": 0.8869607671680074,
        "accuracy od2": 0.8958108333199005,
        "precision od2": 0.9128484883028524,
        "recall od2": 0.969017094017094,
        "f1_score od2": 0.9400945505604527,
        "iou od2": 0.8869607671680074,
        "accuracy is": 0.8708620124549328,
        "precision is": 0.8784722222222222,
        "recall is": 0.9829059829059829,
        "f1_score is": 0.9277594426109277,
        "iou is": 0.8652530779753762,
        "accuracy gpt1": 0.7759240453277882,
        "precision gpt1": 1.0,
        "recall gpt1": 0.7343994803011197,
        "f1_score gpt1": 0.8468631231065823,
        "iou gpt1": 0.7343994803011197,
        "accuracy gpt2": 0.7401926807120481,
        "precision gpt2": 1.0,
        "recall gpt2": 0.6920465690957495,
        "f1_score gpt2": 0.8179994354003952,
        "iou gpt2": 0.6920465690957495,
        "category": "single-person",
        "size10000": 74.4444,
        "aspect ratio": 0.7197640117994101
    },
    "13": {
        "accuracy od1": 0.3676209826719732,
        "precision od1": 0.14121186128048324,
        "recall od1": 0.4679334916864608,
        "f1_score od1": 0.21695235462169385,
        "iou od1": 0.12167501815447195,
        "accuracy od2": 0.8127854900800628,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.8127854900800628,
        "precision is": 0,
        "recall is": 0.0,
        "f1_score is": 0,
        "iou is": 0.0,
        "accuracy gpt1": 0.2830963823813431,
        "precision gpt1": 0.19397348686813093,
        "recall gpt1": 0.8966745843230404,
        "f1_score gpt1": 0.3189499900132038,
        "iou gpt1": 0.1897326005284691,
        "accuracy gpt2": 0.3638941451624607,
        "precision gpt2": 0.19676196509327482,
        "recall gpt2": 0.7779097387173397,
        "f1_score gpt2": 0.31408124039468566,
        "iou gpt2": 0.18629678245481668,
        "category": "none",
        "size10000": 859.9248,
        "aspect ratio": 1.5004177109440267
    },
    "86": {
        "accuracy od1": 0.9213726943346509,
        "precision od1": 0.9248826291079812,
        "recall od1": 0.9780334728033473,
        "f1_score od1": 0.950715765948277,
        "iou od1": 0.9060612321193161,
        "accuracy od2": 0.9213726943346509,
        "precision od2": 0.9248826291079812,
        "recall od2": 0.9780334728033473,
        "f1_score od2": 0.950715765948277,
        "iou od2": 0.9060612321193161,
        "accuracy is": 0.9336281291172596,
        "precision is": 0.9545127276105537,
        "recall is": 0.9601607798993267,
        "f1_score is": 0.9573284232237735,
        "iou is": 0.9181495348551455,
        "accuracy gpt1": 0.6198451910408432,
        "precision gpt1": 1.0,
        "recall gpt1": 0.5097381220398021,
        "f1_score gpt1": 0.675266941462797,
        "iou gpt1": 0.5097381220398021,
        "accuracy gpt2": 0.7911231884057971,
        "precision gpt2": 0.9777777777777777,
        "recall gpt2": 0.747615912325043,
        "f1_score gpt2": 0.8473454256586787,
        "iou gpt2": 0.7351252010107971,
        "category": "single-person",
        "size10000": 121.44,
        "aspect ratio": 1.1857707509881423
    },
    "45": {
        "accuracy od1": 0.2095621910903841,
        "precision od1": 1.0,
        "recall od1": 0.03702492119193481,
        "f1_score od1": 0.07140603940236873,
        "iou od1": 0.03702492119193481,
        "accuracy od2": 0.1791710644391852,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.9934417006476931,
        "precision is": 0.9927325008862804,
        "recall is": 0.9993259184361307,
        "f1_score is": 0.9960182980447176,
        "iou is": 0.9920681782396473,
        "accuracy gpt1": 0.4058403968921891,
        "precision gpt1": 1.0,
        "recall gpt1": 0.27614685914810816,
        "f1_score gpt1": 0.43278225725909003,
        "iou gpt1": 0.27614685914810816,
        "accuracy gpt2": 0.4813968410431904,
        "precision gpt2": 1.0,
        "recall gpt2": 0.3681958121974776,
        "f1_score gpt2": 0.5382209314120227,
        "iou gpt2": 0.3681958121974776,
        "category": "none",
        "size10000": 860.284,
        "aspect ratio": 1.4997912317327766
    },
    "0": {
        "accuracy od1": 0.9846158854166667,
        "precision od1": 0.9965156794425087,
        "recall od1": 0.9820115269464471,
        "f1_score od1": 0.9892104398012859,
        "iou od1": 0.9786512235116614,
        "accuracy od2": 0.9846158854166667,
        "precision od2": 0.9965156794425087,
        "recall od2": 0.9820115269464471,
        "f1_score od2": 0.9892104398012859,
        "iou od2": 0.9786512235116614,
        "accuracy is": 0.9005965169270833,
        "precision is": 0.8903217724952744,
        "recall is": 0.9826325224884244,
        "f1_score is": 0.9342023256803614,
        "iou is": 0.8765287710697228,
        "accuracy gpt1": 0.8875162760416667,
        "precision gpt1": 0.9151238286479251,
        "recall gpt1": 0.9295861314017502,
        "f1_score gpt1": 0.9222982886734944,
        "iou gpt1": 0.8558010801878279,
        "accuracy gpt2": 0.8620003255208334,
        "precision gpt2": 0.9342592592592592,
        "recall gpt2": 0.8689858054924109,
        "f1_score gpt2": 0.9004411555763261,
        "iou gpt2": 0.8189112935090676,
        "category": "group",
        "size10000": 122.88,
        "aspect ratio": 1.3333333333333333
    },
    "68": {
        "accuracy od1": 0.927306,
        "precision od1": 1.0,
        "recall od1": 0.9102598605024381,
        "f1_score od1": 0.9530220252474141,
        "iou od1": 0.9102598605024381,
        "accuracy od2": 0.8832713333333333,
        "precision od2": 1.0,
        "recall od2": 0.8558994300763327,
        "f1_score od2": 0.9223553994422314,
        "iou od2": 0.8558994300763327,
        "accuracy is": 0.417076,
        "precision is": 1.0,
        "recall is": 0.28038516140978953,
        "f1_score is": 0.43797002630218984,
        "iou is": 0.28038516140978953,
        "accuracy gpt1": 0.79635,
        "precision gpt1": 0.97375,
        "recall gpt1": 0.7693352262206037,
        "f1_score gpt1": 0.8595565670149304,
        "iou gpt1": 0.7537038156860374,
        "accuracy gpt2": 0.79635,
        "precision gpt2": 0.97375,
        "recall gpt2": 0.7693352262206037,
        "f1_score gpt2": 0.8595565670149304,
        "iou gpt2": 0.7537038156860374,
        "category": "group",
        "size10000": 600.0,
        "aspect ratio": 1.5
    },
    "35": {
        "accuracy od1": 0.21744173441734418,
        "precision od1": 0.4577213452299245,
        "recall od1": 0.023193940152748217,
        "f1_score od1": 0.04415065110459381,
        "iou od1": 0.022573646139733883,
        "accuracy od2": 0.22078048780487805,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.821719512195122,
        "precision is": 0.8138062790549576,
        "recall is": 1.0,
        "f1_score is": 0.8973464128473222,
        "iou is": 0.8138062790549576,
        "accuracy gpt1": 0.8322168021680216,
        "precision gpt1": 0.8729256198347107,
        "recall gpt1": 0.9183673469387755,
        "f1_score gpt1": 0.8950700978929956,
        "iou gpt1": 0.8100695765280453,
        "accuracy gpt2": 0.839059620596206,
        "precision gpt2": 0.943,
        "recall gpt2": 0.844506002810122,
        "f1_score gpt2": 0.8910394252080611,
        "iou gpt2": 0.8034906248810841,
        "category": "none",
        "size10000": 73.8,
        "aspect ratio": 1.951219512195122
    },
    "76": {
        "accuracy od1": 0.5267778333333333,
        "precision od1": 0.9909173478655767,
        "recall od1": 0.31549979270503287,
        "f1_score od1": 0.4786131598102882,
        "iou od1": 0.3145900484787989,
        "accuracy od2": 0.4919340833333333,
        "precision od2": 0.9897540983606558,
        "recall od2": 0.26473522228980745,
        "f1_score od2": 0.4177361527571955,
        "iou od2": 0.26401169026589805,
        "accuracy is": 0.60247,
        "precision is": 1.0,
        "recall is": 0.4225567186265876,
        "f1_score is": 0.594080662083613,
        "iou is": 0.4225567186265876,
        "accuracy gpt1": 0.5569854166666667,
        "precision gpt1": 0.8522727272727273,
        "recall gpt1": 0.43123405568820417,
        "f1_score gpt1": 0.5726951031554496,
        "iou gpt1": 0.4012423024831971,
        "accuracy gpt2": 0.5699020833333334,
        "precision gpt2": 0.7583333333333333,
        "recall gpt2": 0.5507691097210747,
        "f1_score gpt2": 0.6380960895578379,
        "iou gpt2": 0.46853238665763924,
        "category": "group",
        "size10000": 1200.0,
        "aspect ratio": 1.3333333333333333
    },
    "31": {
        "accuracy od1": 0.6577973720608575,
        "precision od1": 0.8778718258766627,
        "recall od1": 0.5031559654046623,
        "f1_score od1": 0.6396778527399629,
        "iou od1": 0.4702399751620622,
        "accuracy od2": 0.3963001383125864,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.8228354080221301,
        "precision is": 0.9601181683899557,
        "recall is": 0.7371556217423678,
        "f1_score is": 0.8339921460879481,
        "iou is": 0.7152543126444958,
        "accuracy gpt1": 0.8273743660673121,
        "precision gpt1": 0.8777777777777778,
        "recall gpt1": 0.8295625942684767,
        "f1_score gpt1": 0.852989389165366,
        "iou gpt1": 0.7436630325020966,
        "accuracy gpt2": 0.7974066390041494,
        "precision gpt2": 0.79,
        "recall gpt2": 0.9049773755656109,
        "f1_score gpt2": 0.8435889906297552,
        "iou gpt2": 0.7294888960709174,
        "category": "none",
        "size10000": 86.76,
        "aspect ratio": 1.6597510373443984
    },
    "74": {
        "accuracy od1": 0.9345368450553321,
        "precision od1": 0.9438000314843494,
        "recall od1": 0.9699373669150918,
        "f1_score od1": 0.956690210681915,
        "iou od1": 0.9169761661176541,
        "accuracy od2": 0.9345368450553321,
        "precision od2": 0.9438000314843494,
        "recall od2": 0.9699373669150918,
        "f1_score od2": 0.956690210681915,
        "iou od2": 0.9169761661176541,
        "accuracy is": 0.6030897664198094,
        "precision is": 0.9725085910652921,
        "recall is": 0.481145195634815,
        "f1_score is": 0.6437816770207073,
        "iou is": 0.47468882119692235,
        "accuracy gpt1": 0.7698176100316962,
        "precision gpt1": 0.9946428571428572,
        "recall gpt1": 0.6949527548575991,
        "f1_score gpt1": 0.8182192102789094,
        "iou gpt1": 0.692361237714835,
        "accuracy gpt2": 0.8277761519040084,
        "precision gpt2": 0.8278420095020502,
        "recall gpt2": 0.9708616138763198,
        "f1_score gpt2": 0.8936658812864448,
        "iou gpt2": 0.8077721424026937,
        "category": "pair",
        "size10000": 967.6848,
        "aspect ratio": 1.3333333333333333
    },
    "24": {
        "accuracy od1": 0.95779341760222,
        "precision od1": 0.9534115577513287,
        "recall od1": 0.9930693069306931,
        "f1_score od1": 0.9728364373420079,
        "iou od1": 0.9471095672675518,
        "accuracy od2": 0.9786698198414395,
        "precision od2": 0.9976470588235294,
        "recall od2": 0.9742711850802914,
        "f1_score od2": 0.9858205686739161,
        "iou od2": 0.9720376278829798,
        "accuracy is": 0.44671163722200646,
        "precision is": 1.0,
        "recall is": 0.2730110590676902,
        "f1_score is": 0.42892173971785313,
        "iou is": 0.2730110590676902,
        "accuracy gpt1": 0.8420861567191856,
        "precision gpt1": 0.9065573770491804,
        "recall gpt1": 0.883585110103367,
        "f1_score gpt1": 0.8949238460779133,
        "iou gpt1": 0.8098300220321376,
        "accuracy gpt2": 0.8420861567191856,
        "precision gpt2": 0.9300578034682081,
        "recall gpt2": 0.8569550585631811,
        "f1_score gpt2": 0.8920111951877402,
        "iou gpt2": 0.8050723900038725,
        "category": "pair",
        "size10000": 229.187,
        "aspect ratio": 1.7980513728963685
    },
    "50": {
        "accuracy od1": 0.16363260814191197,
        "precision od1": 0.41056543899496833,
        "recall od1": 0.0374797615835172,
        "f1_score od1": 0.06868902846451959,
        "iou od1": 0.03556601162468862,
        "accuracy od2": 0.17706993057233736,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.98406445734738,
        "precision is": 0.9985082048731975,
        "recall is": 0.9821028905220718,
        "f1_score is": 0.990237605450016,
        "iou is": 0.9806639767876584,
        "accuracy gpt1": 0.5961579192414741,
        "precision gpt1": 1.0,
        "recall gpt1": 0.5092631855834446,
        "f1_score gpt1": 0.674850073132309,
        "iou gpt1": 0.5092631855834446,
        "accuracy gpt2": 0.7727408018377198,
        "precision gpt2": 0.9295420231504781,
        "recall gpt2": 0.7832074432020463,
        "f1_score gpt2": 0.8501234367346738,
        "iou gpt2": 0.7393171266318901,
        "category": "none",
        "size10000": 857.4104,
        "aspect ratio": 1.504817762882279
    },
    "42": {
        "accuracy od1": 0.8101279208845066,
        "precision od1": 0.7946683700628128,
        "recall od1": 0.9797752808988764,
        "f1_score od1": 0.8775668081404235,
        "iou od1": 0.78184324421708,
        "accuracy od2": 0.8101279208845066,
        "precision od2": 0.7946683700628128,
        "recall od2": 0.9797752808988764,
        "f1_score od2": 0.8775668081404235,
        "iou od2": 0.78184324421708,
        "accuracy is": 0.806397502844307,
        "precision is": 0.8118484617340452,
        "recall is": 0.9388217998529875,
        "f1_score is": 0.8707305433544026,
        "iou is": 0.7710564898663217,
        "accuracy gpt1": 0.8138072872604218,
        "precision gpt1": 0.9270833333333334,
        "recall gpt1": 0.794392523364486,
        "f1_score gpt1": 0.8556240456936041,
        "iou gpt1": 0.7476774066020953,
        "accuracy gpt2": 0.8602934741386855,
        "precision gpt2": 0.9251559251559252,
        "recall gpt2": 0.8691588785046729,
        "f1_score gpt2": 0.8962836228180362,
        "iou gpt2": 0.8120597296077546,
        "category": "animal",
        "size10000": 27.4232,
        "aspect ratio": 0.8123924268502581
    },
    "89": {
        "accuracy od1": 0.44285017698475765,
        "precision od1": 0.023809523809523808,
        "recall od1": 6.825605772512311e-05,
        "f1_score od1": 0.00013612188742719912,
        "iou od1": 6.806557632095836e-05,
        "accuracy od2": 0.444367189193094,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.611628620963664,
        "precision is": 1.0,
        "recall is": 0.3010287162985715,
        "f1_score is": 0.4627549146724426,
        "iou is": 0.3010287162985715,
        "accuracy gpt1": 0.7792729177201474,
        "precision gpt1": 0.8984615384615384,
        "recall gpt1": 0.6795443095574732,
        "f1_score gpt1": 0.7738176972971973,
        "iou gpt1": 0.631078833540099,
        "accuracy gpt2": 0.7427400130029618,
        "precision gpt2": 0.7146067415730337,
        "recall gpt2": 0.8940568475452196,
        "f1_score gpt2": 0.7943227594969609,
        "iou gpt2": 0.6588187392220732,
        "category": "none",
        "size10000": 221.488,
        "aspect ratio": 1.8642201834862386
    },
    "96": {
        "accuracy od1": 0.8283302955768095,
        "precision od1": 0.8730758993202755,
        "recall od1": 0.8491736055202539,
        "f1_score od1": 0.8609588880529656,
        "iou od1": 0.7558628736247059,
        "accuracy od2": 0.37409797229752034,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.9389730600592362,
        "precision is": 0.9381682938168294,
        "recall is": 0.9661751664721281,
        "f1_score is": 0.951965783861078,
        "iou is": 0.9083346413709934,
        "accuracy gpt1": 0.807567617205481,
        "precision gpt1": 0.7648487215909091,
        "recall gpt1": 1.0,
        "f1_score gpt1": 0.8667583937748978,
        "iou gpt1": 0.7648487215909091,
        "accuracy gpt2": 0.8878283218100069,
        "precision gpt2": 0.8925339728217426,
        "recall gpt2": 0.9331390732904513,
        "f1_score gpt2": 0.9123849706306545,
        "iou gpt2": 0.8388859532032227,
        "category": "none",
        "size10000": 860.284,
        "aspect ratio": 1.4997912317327766
    },
    "69": {
        "accuracy od1": 0.7699566210045662,
        "precision od1": 0.6928660982948847,
        "recall od1": 0.9279432930339666,
        "f1_score od1": 0.7933572600492206,
        "iou od1": 0.6574914295523652,
        "accuracy od2": 0.9086780821917808,
        "precision od2": 0.885625,
        "recall od2": 0.9279432930339666,
        "f1_score od2": 0.9062904132696094,
        "iou od2": 0.8286389954566777,
        "accuracy is": 0.7327465753424658,
        "precision is": 1.0,
        "recall is": 0.4384139320667818,
        "f1_score is": 0.6095796519946769,
        "iou is": 0.4384139320667818,
        "accuracy gpt1": 0.825041095890411,
        "precision gpt1": 0.7486943396226415,
        "recall gpt1": 0.9518518518518518,
        "f1_score gpt1": 0.8381378844204124,
        "iou gpt1": 0.7213746564086156,
        "accuracy gpt2": 0.8749817351598174,
        "precision gpt2": 0.8221844863731657,
        "recall gpt2": 0.9407551333717137,
        "f1_score gpt2": 0.8774824361211796,
        "iou gpt2": 0.7817093151656973,
        "category": "pair",
        "size10000": 87.6,
        "aspect ratio": 1.643835616438356
    },
    "53": {
        "accuracy od1": 0.6152395374449339,
        "precision od1": 0.7262872628726287,
        "recall od1": 0.6495433789954338,
        "f1_score od1": 0.6857749325994033,
        "iou od1": 0.5218093533673012,
        "accuracy od2": 0.49758259911894276,
        "precision od2": 0.6863905325443787,
        "recall od2": 0.41010699925032373,
        "f1_score od2": 0.5134413046144657,
        "iou od2": 0.3453891906241256,
        "accuracy is": 0.46394364904552127,
        "precision is": 1.0,
        "recall is": 0.17068907744383108,
        "f1_score is": 0.2916044588312487,
        "iou is": 0.17068907744383108,
        "accuracy gpt1": 0.7442143906020559,
        "precision gpt1": 0.804,
        "recall gpt1": 0.7990867579908676,
        "f1_score gpt1": 0.8015358497875105,
        "iou gpt1": 0.6688025250028521,
        "accuracy gpt2": 0.720352422907489,
        "precision gpt2": 0.87,
        "recall gpt2": 0.6670415048047434,
        "f1_score gpt2": 0.7551209350769588,
        "iou gpt2": 0.6065817607139538,
        "category": "other",
        "size10000": 108.96,
        "aspect ratio": 1.3215859030837005
    },
    "92": {
        "accuracy od1": 0.8369381223328591,
        "precision od1": 0.8295994274436661,
        "recall od1": 0.913846135469113,
        "f1_score od1": 0.8696872983979834,
        "iou od1": 0.7694218574783391,
        "accuracy od2": 0.40457681365576104,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.9588276434329066,
        "precision is": 0.9932318104906938,
        "recall is": 0.937238577022849,
        "f1_score is": 0.9644231527603221,
        "iou is": 0.9312907635304754,
        "accuracy gpt1": 0.7874170222854433,
        "precision gpt1": 0.7691366666666667,
        "recall gpt1": 0.9187396351575456,
        "f1_score gpt1": 0.8373082076641638,
        "iou gpt1": 0.7201463132220275,
        "accuracy gpt2": 0.7183060692271218,
        "precision gpt2": 0.699503995175637,
        "recall gpt2": 0.9237147595356551,
        "f1_score gpt2": 0.7961245677115371,
        "iou gpt2": 0.6613014489366008,
        "category": "none",
        "size10000": 84.36,
        "aspect ratio": 1.7069701280227596
    },
    "40": {
        "accuracy od1": 0.9289257338446221,
        "precision od1": 1.0,
        "recall od1": 0.8642288625617758,
        "f1_score od1": 0.927170349003367,
        "iou od1": 0.8642288625617758,
        "accuracy od2": 0.7779092875679263,
        "precision od2": 1.0,
        "recall od2": 0.5757464653177203,
        "f1_score od2": 0.7307602815426676,
        "iou od2": 0.5757464653177203,
        "accuracy is": 0.5375399361022364,
        "precision is": 1.0,
        "recall is": 0.11657576938059992,
        "f1_score is": 0.2088094199738334,
        "iou is": 0.11657576938059992,
        "accuracy gpt1": 0.6132665832290363,
        "precision gpt1": 0.6169230769230769,
        "recall gpt1": 0.689177112216137,
        "f1_score gpt1": 0.6510515321088008,
        "iou gpt1": 0.48263632570529896,
        "accuracy gpt2": 0.6150659570469477,
        "precision gpt2": 0.6157894736842106,
        "recall gpt2": 0.7037856046197208,
        "f1_score gpt2": 0.6568535192591484,
        "iou gpt2": 0.4890408668582757,
        "category": "single-person",
        "size10000": 100.0348,
        "aspect ratio": 1.5669586983729662
    },
    "38": {
        "accuracy od1": 0.9381244979919678,
        "precision od1": 1.0,
        "recall od1": 0.9064910630291627,
        "f1_score od1": 0.9509523339583539,
        "iou od1": 0.9064910630291627,
        "accuracy od2": 0.5859196787148594,
        "precision od2": 1.0,
        "recall od2": 0.3742238946378175,
        "f1_score od2": 0.5446330777656079,
        "iou od2": 0.3742238946378175,
        "accuracy is": 0.5795562248995983,
        "precision is": 1.0,
        "recall is": 0.36460716778442026,
        "f1_score is": 0.5343767442998227,
        "iou is": 0.36460716778442026,
        "accuracy gpt1": 0.7499397590361446,
        "precision gpt1": 0.7733333333333333,
        "recall gpt1": 0.8800412709009802,
        "f1_score gpt1": 0.8232438647041289,
        "iou gpt1": 0.6995874846211372,
        "accuracy gpt2": 0.7701004016064257,
        "precision gpt2": 0.7677957658779576,
        "recall gpt2": 0.9354838709677419,
        "f1_score gpt2": 0.8433853603819268,
        "iou gpt2": 0.7291844072286877,
        "category": "animal",
        "size10000": 99.6,
        "aspect ratio": 1.4457831325301205
    },
    "90": {
        "accuracy od1": 0.7967963496637849,
        "precision od1": 0.8009615384615385,
        "recall od1": 0.9899159663865547,
        "f1_score od1": 0.885470517372845,
        "iou od1": 0.7944792230041551,
        "accuracy od2": 0.7952929875120077,
        "precision od2": 0.8009615384615385,
        "recall od2": 0.9873949579831933,
        "f1_score od2": 0.8844605493229475,
        "iou od2": 0.7928545680622441,
        "accuracy is": 0.8012528017931476,
        "precision is": 0.8017324350336862,
        "recall is": 0.9957983193277311,
        "f1_score is": 0.8882894597713819,
        "iou is": 0.7990294484288235,
        "accuracy gpt1": 0.7709173871277618,
        "precision gpt1": 1.0,
        "recall gpt1": 0.7113097339776246,
        "f1_score gpt1": 0.8313044913550699,
        "iou gpt1": 0.7113097339776246,
        "accuracy gpt2": 0.7996557796990074,
        "precision gpt2": 1.0,
        "recall gpt2": 0.7475259011167492,
        "f1_score gpt2": 0.8555248315793728,
        "iou gpt2": 0.7475259011167492,
        "category": "single-person",
        "size10000": 124.92,
        "aspect ratio": 0.8675
    },
    "6": {
        "accuracy od1": 0.9858889622496757,
        "precision od1": 0.9871959026888605,
        "recall od1": 0.9893892519466073,
        "f1_score od1": 0.988291360375232,
        "iou od1": 0.9768537320604268,
        "accuracy od2": 0.9858889622496757,
        "precision od2": 0.9871959026888605,
        "recall od2": 0.9893892519466073,
        "f1_score od2": 0.988291360375232,
        "iou od2": 0.9768537320604268,
        "accuracy is": 0.9793754155604428,
        "precision is": 0.9892241379310345,
        "recall is": 0.9763713153503893,
        "f1_score is": 0.9827557050110796,
        "iou is": 0.9660960595721833,
        "accuracy gpt1": 0.7797889999116571,
        "precision gpt1": 0.900952380952381,
        "recall gpt1": 0.712481460882462,
        "f1_score gpt1": 0.7957089431525552,
        "iou gpt1": 0.6607281010917219,
        "accuracy gpt2": 0.69305485165364,
        "precision gpt2": 0.6992481203007519,
        "recall gpt2": 0.8599137931034483,
        "f1_score gpt2": 0.7713029651108408,
        "iou gpt2": 0.6277405602923264,
        "category": "pair",
        "size10000": 860.284,
        "aspect ratio": 1.4997912317327766
    },
    "20": {
        "accuracy od1": 0.8542133333333334,
        "precision od1": 0.8947901591895803,
        "recall od1": 0.9440559440559441,
        "f1_score od1": 0.9187630949373672,
        "iou od1": 0.8497333846407564,
        "accuracy od2": 0.23008766666666666,
        "precision od2": 1.0,
        "recall od2": 0.11834022963935628,
        "f1_score od2": 0.21163546924806376,
        "iou od2": 0.11834022963935628,
        "accuracy is": 0.377568,
        "precision is": 1.0,
        "recall is": 0.2872263108070968,
        "f1_score is": 0.446271659296654,
        "iou is": 0.2872263108070968,
        "accuracy gpt1": 0.5117466666666667,
        "precision gpt1": 1.0,
        "recall gpt1": 0.4408800806180719,
        "f1_score gpt1": 0.611959435831682,
        "iou gpt1": 0.4408800806180719,
        "accuracy gpt2": 0.7334133333333334,
        "precision gpt2": 1.0,
        "recall gpt2": 0.6947201270345376,
        "f1_score gpt2": 0.8198641368001874,
        "iou gpt2": 0.6947201270345376,
        "category": "single-person",
        "size10000": 600.0,
        "aspect ratio": 1.5
    },
    "93": {
        "accuracy od1": 0.382390180878553,
        "precision od1": 0.9017543859649123,
        "recall od1": 0.33080812737660115,
        "f1_score od1": 0.48404470612361644,
        "iou od1": 0.3193001192574002,
        "accuracy od2": 0.19365094745908698,
        "precision od2": 1.0,
        "recall od2": 0.07925015890110512,
        "f1_score od2": 0.14686151907876077,
        "iou od2": 0.07925015890110512,
        "accuracy is": 0.1342775624461671,
        "precision is": 1.0,
        "recall is": 0.011453173657700587,
        "f1_score is": 0.02264696766194855,
        "iou is": 0.011453173657700587,
        "accuracy gpt1": 0.8499149440137812,
        "precision gpt1": 1.0,
        "recall gpt1": 0.8286216235820305,
        "f1_score gpt1": 0.906280023046943,
        "iou gpt1": 0.8286216235820305,
        "accuracy gpt2": 0.8499149440137812,
        "precision gpt2": 1.0,
        "recall gpt2": 0.8286216235820305,
        "f1_score gpt2": 0.906280023046943,
        "iou gpt2": 0.8286216235820305,
        "category": "pair",
        "size10000": 92.88,
        "aspect ratio": 1.550387596899225
    },
    "11": {
        "accuracy od1": 0.6838935810810811,
        "precision od1": 0.935064935064935,
        "recall od1": 0.6438761084693484,
        "f1_score od1": 0.762619952177691,
        "iou od1": 0.616318287594698,
        "accuracy od2": 0.22387809684684684,
        "precision od2": 0.8034188034188035,
        "recall od2": 0.02097345385483157,
        "f1_score od2": 0.0408797318289592,
        "iou od2": 0.02086637175527919,
        "accuracy is": 0.9224380630630631,
        "precision is": 0.9180365856080719,
        "recall is": 0.9900398406374502,
        "f1_score is": 0.952679654140659,
        "iou is": 0.9096353927498393,
        "accuracy gpt1": 0.9453378378378379,
        "precision gpt1": 0.974,
        "recall gpt1": 0.956210998300704,
        "f1_score gpt1": 0.9650235266142572,
        "iou gpt1": 0.9324110754492352,
        "accuracy gpt2": 0.8786148648648648,
        "precision gpt2": 0.974,
        "recall gpt2": 0.8692827257279128,
        "f1_score gpt2": 0.918666857819798,
        "iou gpt2": 0.8495687609903145,
        "category": "other",
        "size10000": 71.04,
        "aspect ratio": 2.027027027027027
    },
    "61": {
        "accuracy od1": 0.928029211773353,
        "precision od1": 0.9217186580341378,
        "recall od1": 0.9399675568204249,
        "f1_score od1": 0.9307536663860749,
        "iou od1": 0.8704763693135505,
        "accuracy od2": 0.9317356240327686,
        "precision od2": 1.0,
        "recall od2": 0.8673391568362158,
        "f1_score od2": 0.9289572851947537,
        "iou od2": 0.8673391568362158,
        "accuracy is": 0.9372726198258892,
        "precision is": 1.0,
        "recall is": 0.878099418247853,
        "f1_score is": 0.9350936480956517,
        "iou is": 0.878099418247853,
        "accuracy gpt1": 0.7535529017865388,
        "precision gpt1": 0.776555,
        "recall gpt1": 0.7315710448211139,
        "f1_score gpt1": 0.753392138093399,
        "iou gpt1": 0.6043537515808198,
        "accuracy gpt2": 0.7909457445511862,
        "precision gpt2": 0.8911207291932631,
        "recall gpt2": 0.6763781622230756,
        "f1_score gpt2": 0.7690399073724585,
        "iou gpt2": 0.6247480417751865,
        "category": "single-person",
        "size10000": 866.3904,
        "aspect ratio": 0.6714922048997772
    },
    "81": {
        "accuracy od1": 0.5508230519761405,
        "precision od1": 0.5612944354855599,
        "recall od1": 0.7366477272727273,
        "f1_score od1": 0.6371258783250836,
        "iou od1": 0.4674869587677562,
        "accuracy od2": 0.43276047128260653,
        "precision od2": 0.4533439337127829,
        "recall od2": 0.2898863636363636,
        "f1_score od2": 0.35364065455708166,
        "iou od2": 0.2148016200326801,
        "accuracy is": 0.9833558834818622,
        "precision is": 0.988155668358714,
        "recall is": 0.980661412890515,
        "f1_score is": 0.984394277271874,
        "iou is": 0.9692681473156616,
        "accuracy gpt1": 0.8684067887501693,
        "precision gpt1": 0.8319628339140535,
        "recall gpt1": 0.945046439628483,
        "f1_score gpt1": 0.8849064839445575,
        "iou gpt1": 0.793571544631383,
        "accuracy gpt2": 0.8684067887501693,
        "precision gpt2": 0.8319628339140535,
        "recall gpt2": 0.945046439628483,
        "f1_score gpt2": 0.8849064839445575,
        "iou gpt2": 0.793571544631383,
        "category": "other",
        "size10000": 4247.9395,
        "aspect ratio": 1.5655596083701286
    },
    "94": {
        "accuracy od1": 0.5789788848657149,
        "precision od1": 0.5651800210104097,
        "recall od1": 0.6085972850678733,
        "f1_score od1": 0.5860856647685069,
        "iou od1": 0.41451285284023254,
        "accuracy od2": 0.5102273808391209,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.5016173532489773,
        "precision is": 0.49559931923170436,
        "recall is": 0.98989898989899,
        "f1_score is": 0.6605100288389877,
        "iou is": 0.4931056171077459,
        "accuracy gpt1": 0.48977261916087905,
        "precision gpt1": 0.48977261916087905,
        "recall gpt1": 1.0,
        "f1_score gpt1": 0.6575132511654639,
        "iou gpt1": 0.48977261916087905,
        "accuracy gpt2": 0.5461897060222624,
        "precision gpt2": 0.5263929618768328,
        "recall gpt2": 0.7322261072261073,
        "f1_score gpt2": 0.6124786741408725,
        "iou gpt2": 0.441419286843492,
        "category": "none",
        "size10000": 35.7374,
        "aspect ratio": 1.711159737417943
    },
    "3": {
        "accuracy od1": 0.2317931004824022,
        "precision od1": 1.0,
        "recall od1": 0.021429733091293614,
        "f1_score od1": 0.04196026882130768,
        "iou od1": 0.021429733091293614,
        "accuracy od2": 0.2317931004824022,
        "precision od2": 1.0,
        "recall od2": 0.021429733091293614,
        "f1_score od2": 0.04196026882130768,
        "iou od2": 0.021429733091293614,
        "accuracy is": 0.6486017737977782,
        "precision is": 0.9105194238323876,
        "recall is": 0.6125764522218469,
        "f1_score is": 0.7324066292862357,
        "iou is": 0.5777930416864108,
        "accuracy gpt1": 0.7977728491833567,
        "precision gpt1": 0.9418181818181818,
        "recall gpt1": 0.7912776154742128,
        "f1_score gpt1": 0.8600097539716304,
        "iou gpt1": 0.7544009757696019,
        "accuracy gpt2": 0.8701362808965254,
        "precision gpt2": 0.9472307021369385,
        "recall gpt2": 0.8838110588974287,
        "f1_score gpt2": 0.9144225846633647,
        "iou gpt2": 0.8423375171081688,
        "category": "other",
        "size10000": 967.3256,
        "aspect ratio": 1.3338284441143706
    },
    "71": {
        "accuracy od1": 0.7084086677810791,
        "precision od1": 1.0,
        "recall od1": 0.20635521116064523,
        "f1_score od1": 0.3421135155740887,
        "iou od1": 0.20635521116064523,
        "accuracy od2": 0.6452797439827515,
        "precision od2": 1.0,
        "recall od2": 0.03453274642440266,
        "f1_score od2": 0.0667600838035456,
        "iou od2": 0.03453274642440266,
        "accuracy is": 0.6944310792109166,
        "precision is": 1.0,
        "recall is": 0.16831141800385335,
        "f1_score is": 0.2881276608447872,
        "iou is": 0.16831141800385335,
        "accuracy gpt1": 0.7408195313184623,
        "precision gpt1": 0.6283455882352941,
        "recall gpt1": 0.7210682492581603,
        "f1_score gpt1": 0.6715212793126706,
        "iou gpt1": 0.5054813967703137,
        "accuracy gpt2": 0.6236896559706219,
        "precision gpt2": 0.4926324496514807,
        "recall gpt2": 0.8100890207715133,
        "f1_score gpt2": 0.6126806808655111,
        "iou gpt2": 0.44162917103161653,
        "category": "single-person",
        "size10000": 967.6848,
        "aspect ratio": 1.3333333333333333
    },
    "10": {
        "accuracy od1": 0.6604156982655118,
        "precision od1": 0.6450653755297011,
        "recall od1": 0.932972972972973,
        "f1_score od1": 0.7627553053332565,
        "iou od1": 0.6164951109680915,
        "accuracy od2": 0.7065986835905993,
        "precision od2": 1.0,
        "recall od2": 0.4985532931363295,
        "f1_score od2": 0.6653794635396715,
        "iou od2": 0.4985532931363295,
        "accuracy is": 0.8789239689937299,
        "precision is": 1.0,
        "recall is": 0.7930712180462715,
        "f1_score is": 0.8845953357172294,
        "iou is": 0.7930712180462715,
        "accuracy gpt1": 0.7074958870659778,
        "precision gpt1": 1.0,
        "recall gpt1": 0.5000866868293811,
        "f1_score gpt1": 0.6667437171732739,
        "iou gpt1": 0.5000866868293811,
        "accuracy gpt2": 0.8920763407443543,
        "precision gpt2": 0.8607361963190184,
        "recall gpt2": 0.972972972972973,
        "f1_score gpt2": 0.913419717698547,
        "iou gpt2": 0.8406371186525307,
        "category": "pair",
        "size10000": 221.8003,
        "aspect ratio": 1.8634280476626948
    },
    "21": {
        "accuracy od1": 0.9833260325406759,
        "precision od1": 1.0,
        "recall od1": 0.9283592122067621,
        "f1_score od1": 0.9628488368039821,
        "iou od1": 0.9283592122067621,
        "accuracy od2": 0.9833260325406759,
        "precision od2": 1.0,
        "recall od2": 0.9283592122067621,
        "f1_score od2": 0.9628488368039821,
        "iou od2": 0.9283592122067621,
        "accuracy is": 0.975505840634126,
        "precision is": 1.0,
        "recall is": 0.8947592480562837,
        "f1_score is": 0.9444569266244901,
        "iou is": 0.8947592480562837,
        "accuracy gpt1": 0.9143147684605757,
        "precision gpt1": 0.9272727272727272,
        "recall gpt1": 0.6856221012300867,
        "f1_score gpt1": 0.7883448622328708,
        "iou gpt1": 0.6506346877591376,
        "accuracy gpt2": 0.8559084272006675,
        "precision gpt2": 0.6214285714285714,
        "recall gpt2": 0.9746588693957114,
        "f1_score gpt2": 0.7589570011602447,
        "iou gpt2": 0.6115477077504885,
        "category": "other",
        "size10000": 95.88,
        "aspect ratio": 1.5018773466833542
    },
    "60": {
        "accuracy od1": 0.8485467171717171,
        "precision od1": 0.8656778081650432,
        "recall od1": 0.9503424657534246,
        "f1_score od1": 0.9060365620086935,
        "iou od1": 0.8282146647170614,
        "accuracy od2": 0.8485467171717171,
        "precision od2": 0.8656778081650432,
        "recall od2": 0.9503424657534246,
        "f1_score od2": 0.9060365620086935,
        "iou od2": 0.8282146647170614,
        "accuracy is": 0.4054040404040404,
        "precision is": 0.912,
        "recall is": 0.25028264927825833,
        "f1_score is": 0.39277498684767026,
        "iou is": 0.24438083257384183,
        "accuracy gpt1": 0.9412525252525252,
        "precision gpt1": 0.9929824561403509,
        "recall gpt1": 0.9301133226408645,
        "f1_score gpt1": 0.9605202422004399,
        "iou gpt1": 0.9240393908523366,
        "accuracy gpt2": 0.9274141414141415,
        "precision gpt2": 0.9472727272727273,
        "recall gpt2": 0.958904109589041,
        "f1_score gpt2": 0.9530529314152065,
        "iou gpt2": 0.9103162519032524,
        "category": "pair",
        "size10000": 79.2,
        "aspect ratio": 1.8181818181818181
    },
    "23": {
        "accuracy od1": 0.8715852298081214,
        "precision od1": 0.860367545076283,
        "recall od1": 0.9243243243243243,
        "f1_score od1": 0.8911999470701935,
        "iou od1": 0.8037517176477007,
        "accuracy od2": 0.9155031236055332,
        "precision od2": 0.9269650328750747,
        "recall od2": 0.9243243243243243,
        "f1_score od2": 0.9256427952253846,
        "iou od2": 0.8615782452164696,
        "accuracy is": 0.9331793842034806,
        "precision is": 0.9590704106420603,
        "recall is": 0.9219068905684793,
        "f1_score is": 0.9401215203843547,
        "iou is": 0.8870087830496197,
        "accuracy gpt1": 0.7058846497099509,
        "precision gpt1": 0.852,
        "recall gpt1": 0.5846542952092463,
        "f1_score gpt1": 0.6934520868094112,
        "iou gpt1": 0.5307513638103035,
        "accuracy gpt2": 0.7785397144132084,
        "precision gpt2": 0.7396369230769231,
        "recall gpt2": 0.9425913399798057,
        "f1_score gpt2": 0.828871293786017,
        "iou gpt2": 0.7077542283679361,
        "category": "single-person",
        "size10000": 89.64,
        "aspect ratio": 1.606425702811245
    },
    "95": {
        "accuracy od1": 0.7464102552180443,
        "precision od1": 0.8234767268185884,
        "recall od1": 0.7845799466333748,
        "f1_score od1": 0.8035579056977241,
        "iou od1": 0.6716228971919711,
        "accuracy od2": 0.6504463642239074,
        "precision od2": 0.9864176570458404,
        "recall od2": 0.4778092428884796,
        "f1_score od2": 0.6437792857186856,
        "iou od2": 0.47468622101074137,
        "accuracy is": 0.6931519126242032,
        "precision is": 0.979214551795197,
        "recall is": 0.547451369992483,
        "f1_score is": 0.702278527667836,
        "iou is": 0.5411627553682653,
        "accuracy gpt1": 0.7480977212176444,
        "precision gpt1": 1.0,
        "recall gpt1": 0.6189473499118615,
        "f1_score gpt1": 0.7646293746928312,
        "iou gpt1": 0.6189473499118615,
        "accuracy gpt2": 0.7883669811364619,
        "precision gpt2": 0.9325301204819277,
        "recall gpt2": 0.732888171863392,
        "f1_score gpt2": 0.8207431110235929,
        "iou gpt2": 0.695983308383296,
        "category": "pair",
        "size10000": 860.284,
        "aspect ratio": 1.4997912317327766
    },
    "88": {
        "accuracy od1": 0.7053094181459566,
        "precision od1": 0.9809251856082238,
        "recall od1": 0.6684357014472742,
        "f1_score od1": 0.7950781659190249,
        "iou od1": 0.6598587090302431,
        "accuracy od2": 0.14473989151873767,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.8877835305719921,
        "precision is": 0.9206664703230318,
        "recall is": 0.9507154213036566,
        "f1_score is": 0.9354496964299137,
        "iou is": 0.8787275653323102,
        "accuracy gpt1": 0.8959824950690335,
        "precision gpt1": 0.980909090909091,
        "recall gpt1": 0.8958138448832278,
        "f1_score gpt1": 0.9364322537436333,
        "iou gpt1": 0.8804631929087399,
        "accuracy gpt2": 0.8547990631163708,
        "precision gpt2": 1.0,
        "recall gpt2": 0.8302259915507209,
        "f1_score gpt2": 0.907238773117066,
        "iou gpt2": 0.8302259915507209,
        "category": "none",
        "size10000": 81.12,
        "aspect ratio": 1.7751479289940828
    },
    "83": {
        "accuracy od1": 0.6739434162859642,
        "precision od1": 1.0,
        "recall od1": 0.6160767846430714,
        "f1_score od1": 0.7624350408314773,
        "iou od1": 0.6160767846430714,
        "accuracy od2": 0.31562188431605004,
        "precision od2": 1.0,
        "recall od2": 0.1941624251214666,
        "f1_score od2": 0.3251859563437812,
        "iou od2": 0.1941624251214666,
        "accuracy is": 0.6832401418313071,
        "precision is": 1.0,
        "recall is": 0.6270234391255624,
        "f1_score is": 0.7707614088983914,
        "iou is": 0.6270234391255624,
        "accuracy gpt1": 0.9250117393597584,
        "precision gpt1": 0.9438201182310363,
        "recall gpt1": 0.9694061187762447,
        "f1_score gpt1": 0.956442034861979,
        "iou gpt1": 0.9165202766053151,
        "accuracy gpt2": 0.8125978624444654,
        "precision gpt2": 1.0,
        "recall gpt2": 0.7793388178348103,
        "f1_score gpt2": 0.8759869790095957,
        "iou gpt2": 0.7793388178348103,
        "category": "single-person",
        "size10000": 967.6848,
        "aspect ratio": 1.3333333333333333
    },
    "27": {
        "accuracy od1": 0.8452717186370974,
        "precision od1": 0.7463686311497474,
        "recall od1": 0.9682466635987115,
        "f1_score od1": 0.8429516978401838,
        "iou od1": 0.728536307660345,
        "accuracy od2": 0.8452717186370974,
        "precision od2": 0.7463686311497474,
        "recall od2": 0.9682466635987115,
        "f1_score od2": 0.8429516978401838,
        "iou od2": 0.728536307660345,
        "accuracy is": 0.9024479382410361,
        "precision is": 0.8284806361729439,
        "recall is": 0.9742291762540267,
        "f1_score is": 0.8954630436437775,
        "iou is": 0.8107135198063785,
        "accuracy gpt1": 0.7345946232105076,
        "precision gpt1": 0.7588235294117647,
        "recall gpt1": 0.558728783736228,
        "f1_score gpt1": 0.6435821081679425,
        "iou gpt1": 0.474471851221811,
        "accuracy gpt2": 0.8160470585175843,
        "precision gpt2": 0.7941767068273092,
        "recall gpt2": 0.7708508161663192,
        "f1_score gpt2": 0.7823399315905875,
        "iou gpt2": 0.6424945285530561,
        "category": "single-person",
        "size10000": 861.3616,
        "aspect ratio": 1.4979149291075897
    },
    "48": {
        "accuracy od1": 0.7020207583107423,
        "precision od1": 0.6580332823843275,
        "recall od1": 1.0,
        "f1_score od1": 0.793751596395032,
        "iou od1": 0.6580332823843275,
        "accuracy od2": 0.7578963852785633,
        "precision od2": 0.7469040247678018,
        "recall od2": 0.8738965952080706,
        "f1_score od2": 0.8054252647083796,
        "iou od2": 0.6742359778032295,
        "accuracy is": 0.9058270730212393,
        "precision is": 0.9318540306070084,
        "recall is": 0.9017020692719325,
        "f1_score is": 0.9165301325802984,
        "iou is": 0.8459212020017016,
        "accuracy gpt1": 0.852805863638339,
        "precision gpt1": 0.9062857142857143,
        "recall gpt1": 0.8290155440414507,
        "f1_score gpt1": 0.8659302710468215,
        "iou gpt1": 0.7635599901305298,
        "accuracy gpt2": 0.7878304927776004,
        "precision gpt2": 0.7499533363474596,
        "recall gpt2": 0.9450777202072539,
        "f1_score gpt2": 0.8362846056846901,
        "iou gpt2": 0.7186332756014893,
        "category": "group",
        "size10000": 266.9196,
        "aspect ratio": 1.5530129672006103
    },
    "12": {
        "accuracy od1": 0.6840803327349517,
        "precision od1": 0.5991221501018971,
        "recall od1": 0.9860759493670886,
        "f1_score od1": 0.7453704911032643,
        "iou od1": 0.5940960943591301,
        "accuracy od2": 0.8358550401859204,
        "precision od2": 0.8592085235920852,
        "recall od2": 0.7773258873169521,
        "f1_score od2": 0.8162187406991576,
        "iou od2": 0.6895013198479147,
        "accuracy is": 0.8141207979828828,
        "precision is": 0.8178319435535599,
        "recall is": 0.7765822784810127,
        "f1_score is": 0.7966735185401614,
        "iou is": 0.6620593253907797,
        "accuracy gpt1": 0.8388862094137102,
        "precision gpt1": 0.7951674107142858,
        "recall gpt1": 0.8841772151898735,
        "f1_score gpt1": 0.837313432835821,
        "iou gpt1": 0.7201540436456996,
        "accuracy gpt2": 0.7863186307737,
        "precision gpt2": 0.7030264046641427,
        "recall gpt2": 0.9424050632911393,
        "f1_score gpt2": 0.8053032366108355,
        "iou gpt2": 0.6740649688598122,
        "category": "group",
        "size10000": 859.2064,
        "aspect ratio": 1.5016722408026757
    },
    "29": {
        "accuracy od1": 0.7509869335557409,
        "precision od1": 0.7258198128391935,
        "recall od1": 0.9891696750902527,
        "f1_score od1": 0.83727504278411,
        "iou od1": 0.7200972487843902,
        "accuracy od2": 0.7509869335557409,
        "precision od2": 0.7258198128391935,
        "recall od2": 0.9891696750902527,
        "f1_score od2": 0.83727504278411,
        "iou od2": 0.7200972487843902,
        "accuracy is": 0.8270586599944398,
        "precision is": 0.8105448857849556,
        "recall is": 0.9565499212300983,
        "f1_score is": 0.8775156189392314,
        "iou is": 0.7817619859529473,
        "accuracy gpt1": 0.7902224075618571,
        "precision gpt1": 1.0,
        "recall gpt1": 0.6760904372910022,
        "f1_score gpt1": 0.8067469657350232,
        "iou gpt1": 0.6760904372910022,
        "accuracy gpt2": 0.7902224075618571,
        "precision gpt2": 1.0,
        "recall gpt2": 0.6760904372910022,
        "f1_score gpt2": 0.8067469657350232,
        "iou gpt2": 0.6760904372910022,
        "category": "single-person",
        "size10000": 143.88,
        "aspect ratio": 0.9991666666666666
    },
    "47": {
        "accuracy od1": 0.9812134537456958,
        "precision od1": 0.9995726495726496,
        "recall od1": 0.9728410889807809,
        "f1_score od1": 0.9860257266701441,
        "iou od1": 0.9724366313871753,
        "accuracy od2": 0.9812134537456958,
        "precision od2": 0.9995726495726496,
        "recall od2": 0.9728410889807809,
        "f1_score od2": 0.9860257266701441,
        "iou od2": 0.9724366313871753,
        "accuracy is": 0.9796323525552196,
        "precision is": 1.0,
        "recall is": 0.970104431884529,
        "f1_score is": 0.9848253891359078,
        "iou is": 0.970104431884529,
        "accuracy gpt1": 0.633647585191484,
        "precision gpt1": 1.0,
        "recall gpt1": 0.4622690911717438,
        "f1_score gpt1": 0.6322626853875697,
        "iou gpt1": 0.4622690911717438,
        "accuracy gpt2": 0.7240946436444948,
        "precision gpt2": 0.9903571428571428,
        "recall gpt2": 0.6008775889777713,
        "f1_score gpt2": 0.747951763899347,
        "iou gpt2": 0.5973825467210024,
        "category": "single-person",
        "size10000": 1219.2768,
        "aspect ratio": 0.75
    },
    "59": {
        "accuracy od1": 0.7185350421981364,
        "precision od1": 0.6811820701134662,
        "recall od1": 0.9159663865546218,
        "f1_score od1": 0.7813173243134443,
        "iou od1": 0.6411162970485996,
        "accuracy od2": 0.8169853358956103,
        "precision od2": 0.9390519187358917,
        "recall od2": 0.7128740911846572,
        "f1_score od2": 0.8104791366245926,
        "iou od2": 0.6813492403359461,
        "accuracy is": 0.7122867593099342,
        "precision is": 0.66587077936801,
        "recall is": 0.9551820728291317,
        "f1_score is": 0.7847095551647513,
        "iou is": 0.6456971323189583,
        "accuracy gpt1": 0.7605310724664296,
        "precision gpt1": 0.892,
        "recall gpt1": 0.6414256065775441,
        "f1_score gpt1": 0.7462398418455471,
        "iou gpt1": 0.5952014322611906,
        "accuracy gpt2": 0.8287659070443426,
        "precision gpt2": 0.8247693778769021,
        "recall gpt2": 0.8736907085108925,
        "f1_score gpt2": 0.8485254942291671,
        "iou gpt2": 0.7369034138199505,
        "category": "group",
        "size10000": 823.3302,
        "aspect ratio": 1.4997865983781478
    },
    "58": {
        "accuracy od1": 0.9096545403271291,
        "precision od1": 0.9354707087543841,
        "recall od1": 0.9524327229207878,
        "f1_score od1": 0.9438755175745408,
        "iou od1": 0.893716160624237,
        "accuracy od2": 0.20236463620981388,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.9786379018612521,
        "precision is": 0.9786885502475468,
        "recall is": 0.9948822927328557,
        "f1_score is": 0.9867189842258351,
        "iou is": 0.9737861154656728,
        "accuracy gpt1": 0.8030414551607445,
        "precision gpt1": 0.9813559322033898,
        "recall gpt1": 0.7676560900716479,
        "f1_score gpt1": 0.8614507485248213,
        "iou gpt1": 0.7566214174825284,
        "accuracy gpt2": 0.8967808798646362,
        "precision gpt2": 0.956,
        "recall gpt2": 0.9125959238654865,
        "f1_score gpt2": 0.933793863159694,
        "iou gpt2": 0.8758098747461587,
        "category": "none",
        "size10000": 141.84,
        "aspect ratio": 1.015228426395939
    },
    "32": {
        "accuracy od1": 0.6243675099866844,
        "precision od1": 0.5705423406279734,
        "recall od1": 1.0,
        "f1_score od1": 0.7265545485387486,
        "iou od1": 0.5705423406279734,
        "accuracy od2": 0.9339658233466489,
        "precision od2": 0.9315065463552725,
        "recall od2": 0.936539701598737,
        "f1_score od2": 0.9340163434565191,
        "iou od2": 0.8762013729977117,
        "accuracy is": 0.9271660008877053,
        "precision is": 0.9532871972318339,
        "recall is": 0.8980566117448247,
        "f1_score is": 0.9248480657290327,
        "iou is": 0.8602022060781094,
        "accuracy gpt1": 0.6636240568131381,
        "precision gpt1": 0.6025090909090909,
        "recall gpt1": 0.9578947368421052,
        "f1_score gpt1": 0.7397319550453754,
        "iou gpt1": 0.5869639859606287,
        "accuracy gpt2": 0.7357501109631602,
        "precision gpt2": 0.66276,
        "recall gpt2": 0.9578947368421052,
        "f1_score gpt2": 0.783454120556864,
        "iou gpt2": 0.6439988279895237,
        "category": "pair",
        "size10000": 90.12,
        "aspect ratio": 1.5978695073235685
    },
    "5": {
        "accuracy od1": 0.8151444444444444,
        "precision od1": 0.8266666666666667,
        "recall od1": 0.9770797962648556,
        "f1_score od1": 0.8956018097275995,
        "iou od1": 0.8109410334208343,
        "accuracy od2": 0.8151444444444444,
        "precision od2": 0.8266666666666667,
        "recall od2": 0.9770797962648556,
        "f1_score od2": 0.8956018097275995,
        "iou od2": 0.8109410334208343,
        "accuracy is": 0.8132222222222222,
        "precision is": 0.8259478260869565,
        "recall is": 0.9753820033955858,
        "f1_score is": 0.8944665570106601,
        "iou is": 0.8090814101399236,
        "accuracy gpt1": 0.7440444444444444,
        "precision gpt1": 1.0,
        "recall gpt1": 0.684593898899173,
        "f1_score gpt1": 0.8127702461068306,
        "iou gpt1": 0.684593898899173,
        "accuracy gpt2": 0.7509888888888889,
        "precision gpt2": 1.0,
        "recall gpt2": 0.6931513226354127,
        "f1_score gpt2": 0.8187706714323837,
        "iou gpt2": 0.6931513226354127,
        "category": "other",
        "size10000": 144.0,
        "aspect ratio": 1.0
    },
    "64": {
        "accuracy od1": 0.9654075889615106,
        "precision od1": 0.9971509971509972,
        "recall od1": 0.9454198358536512,
        "f1_score od1": 0.9705966094318936,
        "iou od1": 0.942872947889011,
        "accuracy od2": 0.9654075889615106,
        "precision od2": 0.9971509971509972,
        "recall od2": 0.9454198358536512,
        "f1_score od2": 0.9705966094318936,
        "iou od2": 0.942872947889011,
        "accuracy is": 0.9729012345679012,
        "precision is": 0.9962264150943396,
        "recall is": 0.9587589814508614,
        "f1_score is": 0.9771336652623516,
        "iou is": 0.9552896914072095,
        "accuracy gpt1": 0.830766158315178,
        "precision gpt1": 0.8109298701298702,
        "recall gpt1": 0.9386044554008959,
        "f1_score gpt1": 0.8701085517606566,
        "iou gpt1": 0.7700815446621052,
        "accuracy gpt2": 0.8440631808278867,
        "precision gpt2": 0.8436490250696379,
        "recall gpt2": 0.9105312208760484,
        "f1_score gpt2": 0.8758151034512672,
        "iou gpt2": 0.7790667764173269,
        "category": "single-person",
        "size10000": 110.16,
        "aspect ratio": 0.765
    },
    "70": {
        "accuracy od1": 0.28372347648272733,
        "precision od1": 1.0,
        "recall od1": 0.22452679440433476,
        "f1_score od1": 0.3667160170448614,
        "iou od1": 0.22452679440433476,
        "accuracy od2": 0.28372347648272733,
        "precision od2": 1.0,
        "recall od2": 0.22452679440433476,
        "f1_score od2": 0.3667160170448614,
        "iou od2": 0.22452679440433476,
        "accuracy is": 0.28089803591123896,
        "precision is": 1.0,
        "recall is": 0.2214678452621334,
        "f1_score is": 0.3626257475727578,
        "iou is": 0.2214678452621334,
        "accuracy gpt1": 0.723497951111123,
        "precision gpt1": 0.9350835856116562,
        "recall gpt1": 0.7529162248144221,
        "f1_score gpt1": 0.8341702396127055,
        "iou gpt1": 0.7155163369097646,
        "accuracy gpt2": 0.713259544709251,
        "precision gpt2": 1.0,
        "recall gpt2": 0.6895618762620026,
        "f1_score gpt2": 0.816261169182621,
        "iou gpt2": 0.6895618762620026,
        "category": "group",
        "size10000": 298.1128,
        "aspect ratio": 0.7831881086622245
    },
    "7": {
        "accuracy od1": 0.9505676193433644,
        "precision od1": 0.9595278308392398,
        "recall od1": 0.9804336821204421,
        "f1_score od1": 0.9698681113023795,
        "iou od1": 0.9414989691548801,
        "accuracy od2": 0.9505676193433644,
        "precision od2": 0.9595278308392398,
        "recall od2": 0.9804336821204421,
        "f1_score od2": 0.9698681113023795,
        "iou od2": 0.9414989691548801,
        "accuracy is": 0.9608886417507659,
        "precision is": 0.996279564177518,
        "recall is": 0.9553669636845287,
        "f1_score is": 0.9753944360528182,
        "iou is": 0.9519706610758748,
        "accuracy gpt1": 0.6418758563409074,
        "precision gpt1": 1.0,
        "recall gpt1": 0.5586491503126633,
        "f1_score gpt1": 0.7168375900382699,
        "iou gpt1": 0.5586491503126633,
        "accuracy gpt2": 0.828946373169024,
        "precision gpt2": 1.0,
        "recall gpt2": 0.7891941526963422,
        "f1_score gpt2": 0.882178327608566,
        "iou gpt2": 0.7891941526963422,
        "category": "single-person",
        "size10000": 1504.5118,
        "aspect ratio": 0.9628130533771819
    },
    "52": {
        "accuracy od1": 0.6100283911132395,
        "precision od1": 0.9950248756218906,
        "recall od1": 0.4489337822671156,
        "f1_score od1": 0.6187161639597835,
        "iou od1": 0.4479283314669653,
        "accuracy od2": 0.2952034411397493,
        "precision od2": 0,
        "recall od2": 0.0,
        "f1_score od2": 0,
        "iou od2": 0.0,
        "accuracy is": 0.7323389317416067,
        "precision is": 0.7247581171721968,
        "recall is": 1.0,
        "f1_score is": 0.840417111195237,
        "iou is": 0.7247581171721968,
        "accuracy gpt1": 0.704394636474029,
        "precision gpt1": 0.9557142857142857,
        "recall gpt1": 0.6087906087906088,
        "f1_score gpt1": 0.7437878703652232,
        "iou gpt1": 0.5920877953801221,
        "accuracy gpt2": 0.7684071901349433,
        "precision gpt2": 0.9273011583011583,
        "recall gpt2": 0.7285194285194285,
        "f1_score gpt2": 0.8159783919683353,
        "iou gpt2": 0.6891583620039082,
        "category": "none",
        "size10000": 46.7752,
        "aspect ratio": 2.0995762711864407
    },
    "9": {
        "accuracy od1": 0.7145983787767133,
        "precision od1": 0.775477459374454,
        "recall od1": 0.7826571730887929,
        "f1_score od1": 0.7790507745644446,
        "iou od1": 0.6380697561657651,
        "accuracy od2": 0.5655994558131625,
        "precision od2": 1.0,
        "recall od2": 0.3242870999030068,
        "f1_score od2": 0.48975346800064457,
        "iou od2": 0.3242870999030068,
        "accuracy is": 0.5951476673657956,
        "precision is": 1.0,
        "recall is": 0.37024953707785907,
        "f1_score is": 0.5404118404118403,
        "iou is": 0.37024953707785907,
        "accuracy gpt1": 0.7425882886457684,
        "precision gpt1": 1.0,
        "recall gpt1": 0.5995943920289216,
        "f1_score gpt1": 0.7496830384212558,
        "iou gpt1": 0.5995943920289216,
        "accuracy gpt2": 0.8332860948925798,
        "precision gpt2": 0.7998500749625187,
        "recall gpt2": 0.9878758486905916,
        "f1_score gpt2": 0.8839750670664351,
        "iou gpt2": 0.7920746579942733,
        "category": "single-person",
        "size10000": 352.82,
        "aspect ratio": 1.4993481095176011
    },
    "77": {
        "accuracy od1": 0.6992225823100279,
        "precision od1": 0.8981809518628501,
        "recall od1": 0.7007429171726822,
        "f1_score od1": 0.7872719302601432,
        "iou od1": 0.6491743284453056,
        "accuracy od2": 0.3845118588745112,
        "precision od2": 0.9877300613496932,
        "recall od2": 0.2278997435017066,
        "f1_score od2": 0.37034864846545446,
        "iou od2": 0.22725636874213567,
        "accuracy is": 0.3803355636045771,
        "precision is": 0.9787234042553191,
        "recall is": 0.22469519789415573,
        "f1_score is": 0.36548288120192357,
        "iou is": 0.2236029693409863,
        "accuracy gpt1": 0.5405245244593646,
        "precision gpt1": 1.0,
        "recall gpt1": 0.42149668203080615,
        "f1_score gpt1": 0.5930322418039546,
        "iou gpt1": 0.42149668203080615,
        "accuracy gpt2": 0.7048470040126283,
        "precision gpt2": 1.0,
        "recall gpt2": 0.6283871575815105,
        "f1_score gpt2": 0.7717908541047382,
        "iou gpt2": 0.6283871575815105,
        "category": "single-person",
        "size10000": 860.284,
        "aspect ratio": 1.4997912317327766
    }
}